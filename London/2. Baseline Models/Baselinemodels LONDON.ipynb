{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c7fbd13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#insert file_path for the data\n",
    "file_path = 'C:/Users/anton/Documents/2de_master/Thesis/Code/analysis/Code/Airbnb_Spatiotemporal_Analysis/London Airbnb_Spatiotemporal_Analysis/Data Cleaning Listings/FINAL_TRAIN_DATA_LONDON.csv'\n",
    "#read data, and quickly check if it is correctly read in\n",
    "train_data_london= pd.read_csv(file_path)\n",
    "\n",
    "import pandas as pd\n",
    "#insert file_path for the data\n",
    "file_path = 'C:/Users/anton/Documents/2de_master/Thesis/Code/analysis/Code/Airbnb_Spatiotemporal_Analysis/London Airbnb_Spatiotemporal_Analysis/Data Cleaning Listings/FINAL_VALID_DATA_LONDON.csv'\n",
    "#read data, and quickly check if it is correctly read in\n",
    "valid_data_london= pd.read_csv(file_path)\n",
    "\n",
    "import pandas as pd\n",
    "#insert file_path for the data\n",
    "file_path = 'C:/Users/anton/Documents/2de_master/Thesis/Code/analysis/Code/Airbnb_Spatiotemporal_Analysis/London Airbnb_Spatiotemporal_Analysis/Data Cleaning Listings/FINAL_TEST_DATA_LONDON.csv'\n",
    "#read data, and quickly check if it is correctly read in\n",
    "test_data_london= pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2694802b",
   "metadata": {},
   "source": [
    "### Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7aea2d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3156848 entries, 0 to 3156847\n",
      "Columns: 146 entries, id to kitchen_amenities\n",
      "dtypes: bool(116), float64(10), int64(19), object(1)\n",
      "memory usage: 1.0+ GB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 334014 entries, 0 to 334013\n",
      "Columns: 146 entries, id to kitchen_amenities\n",
      "dtypes: bool(116), float64(10), int64(19), object(1)\n",
      "memory usage: 113.4+ MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 338147 entries, 0 to 338146\n",
      "Columns: 146 entries, id to kitchen_amenities\n",
      "dtypes: bool(116), float64(10), int64(19), object(1)\n",
      "memory usage: 114.8+ MB\n"
     ]
    }
   ],
   "source": [
    "train_data_london.info()\n",
    "valid_data_london.info()\n",
    "test_data_london.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b69d0bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3829009 entries, 0 to 3829008\n",
      "Columns: 146 entries, id to kitchen_amenities\n",
      "dtypes: bool(116), float64(10), int64(19), object(1)\n",
      "memory usage: 1.3+ GB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Concatenate the datasets\n",
    "combined_data = pd.concat([train_data_london, valid_data_london, test_data_london], ignore_index=True)\n",
    "\n",
    "# Display information about the combined dataset\n",
    "combined_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1449a111",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data.to_csv('Combined_data_london.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e97298c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anton\\AppData\\Local\\Temp\\ipykernel_14520\\38797166.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  date_price_data['day_of_week'] = pd.to_datetime(date_price_data['date']).dt.day_name()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  day_of_week       price\n",
      "0      Friday  146.617221\n",
      "1      Monday  142.594550\n",
      "2    Saturday  147.363518\n",
      "3      Sunday  143.023238\n",
      "4    Thursday  142.835944\n",
      "5     Tuesday  142.547966\n",
      "6   Wednesday  142.598235\n"
     ]
    }
   ],
   "source": [
    "# Assuming the necessary imports have been done\n",
    "# import pandas as pd\n",
    "\n",
    "# 1. Extract Date and Price Columns\n",
    "date_price_data = combined_data[['date', 'price']]\n",
    "\n",
    "# 2. Convert Date to Day of the Week\n",
    "date_price_data['day_of_week'] = pd.to_datetime(date_price_data['date']).dt.day_name()\n",
    "\n",
    "# 3. Group By Day of the Week and 4. Calculate Mean Price\n",
    "average_price_per_day = date_price_data.groupby('day_of_week')['price'].mean().reset_index()\n",
    "\n",
    "# 5. Output Results\n",
    "print(average_price_per_day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a01b7d1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique IDs in the combined dataset: 58284\n"
     ]
    }
   ],
   "source": [
    "# Count the unique IDs in the combined dataset\n",
    "unique_ids_count = combined_data['id'].nunique()\n",
    "\n",
    "# Display the count of unique IDs\n",
    "print(f\"Number of unique IDs in the combined dataset: {unique_ids_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed14f88f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'date', 'available', 'price', 'season_Autumn', 'is_holiday', 'is_school_holiday', 'host_id', 'host_response_time', 'host_is_superhost', 'host_listings_count', 'host_total_listings_count', 'host_identity_verified', 'latitude', 'longitude', 'accommodates', 'bathrooms', 'bedrooms', 'beds', 'availability_90', 'availability_365', 'number_of_reviews', 'number_of_reviews_ltm', 'number_of_reviews_l30d', 'review_scores_rating', 'instant_bookable', 'calculated_host_listings_count', 'calculated_host_listings_count_entire_homes', 'calculated_host_listings_count_private_rooms', 'reviews_per_month', 'conditioner', 'broadcast', 'tv', 'Central heating', 'game console', 'Extra pillows and blankets', 'view', 'Bathtub', 'Private patio or balcony', 'coffee', 'Luggage dropoff allowed', 'oven', 'Toaster', 'Essentials', 'Fire extinguisher', 'toys children', 'Hair dryer', 'Washer', 'Long term stays allowed', 'Shower gel', 'backyard', 'Hangers', 'soap', 'bbq', 'Portable fans', 'Dryer', 'stove', 'Lockbox', 'Free washer – In unit', 'Kitchen', 'Outdoor dining area', 'Iron', 'Laundromat nearby', 'shampoo', 'sauna', 'Wine glasses', 'sound system', 'Freezer', 'Room-darkening shades', 'Hot water kettle', 'Host greets you', 'gym', 'Heating', 'Lock on bedroom door', 'Books and reading material', 'exercise equipment', 'Security cameras on property', 'hot tub', 'wifi', 'pool', 'Hot water', 'Drying rack for clothing', 'Elevator', 'clothing storage', 'crib', 'Private entrance', 'Bed linens', 'First aid kit', 'Microwave', 'Pets allowed', 'Dedicated workspace', 'parking', 'Self check-in', 'Outdoor furniture', 'Dining table', 'Cleaning products', 'Carbon monoxide alarm', 'Dishwasher', 'Smoke alarm', 'total_amenities', 'listing_reviewed', 'neighbourhood_Barking and Dagenham', 'neighbourhood_Barnet', 'neighbourhood_Bexley', 'neighbourhood_Brent', 'neighbourhood_Bromley', 'neighbourhood_Camden', 'neighbourhood_City of London', 'neighbourhood_Croydon', 'neighbourhood_Ealing', 'neighbourhood_Enfield', 'neighbourhood_Greenwich', 'neighbourhood_Hackney', 'neighbourhood_Hammersmith and Fulham', 'neighbourhood_Haringey', 'neighbourhood_Harrow', 'neighbourhood_Havering', 'neighbourhood_Hillingdon', 'neighbourhood_Hounslow', 'neighbourhood_Islington', 'neighbourhood_Kensington and Chelsea', 'neighbourhood_Kingston upon Thames', 'neighbourhood_Lambeth', 'neighbourhood_Lewisham', 'neighbourhood_Merton', 'neighbourhood_Newham', 'neighbourhood_Redbridge', 'neighbourhood_Richmond upon Thames', 'neighbourhood_Southwark', 'neighbourhood_Sutton', 'neighbourhood_Tower Hamlets', 'neighbourhood_Waltham Forest', 'neighbourhood_Wandsworth', 'neighbourhood_Westminster', 'property_type_Apartment', 'property_type_Hotel', 'property_type_House', 'property_type_Other', 'room_type_Entire home/apt', 'room_type_Private room', 'nearby_airbnbs_count', 'luxury_amenities_score', 'nearby_restaurants_bars', 'nearby_transport', 'mean_price_neighbors', 'kitchen_amenities']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming the combined_data dataframe is already loaded\n",
    "# combined_data = pd.read_csv('path_to_combined_data.csv')\n",
    "\n",
    "# Extract the column names and store them in a set\n",
    "column_names = list(combined_data.columns)\n",
    "\n",
    "# Print the set of column names\n",
    "print(column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f44a71ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of columns starting with 'neighbourhood': 33\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming the combined_data dataframe is already loaded\n",
    "# combined_data = pd.read_csv('path_to_combined_data.csv')\n",
    "\n",
    "# Count the number of columns starting with 'neighbourhood'\n",
    "neighbourhood_columns = [col for col in combined_data.columns if col.startswith('neighbourhood')]\n",
    "count_neighbourhood_columns = len(neighbourhood_columns)\n",
    "\n",
    "# Print the result\n",
    "print(f\"Number of columns starting with 'neighbourhood': {count_neighbourhood_columns}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0aa233a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First date in the dataset: 2023-10-15 00:00:00\n",
      "Last date in the dataset: 2024-03-12 00:00:00\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming the dataset is already loaded into a DataFrame named 'df'\n",
    "# Ensure the 'date' column is in datetime format\n",
    "combined_data['date'] = pd.to_datetime(combined_data['date'])\n",
    "\n",
    "# Get the first and last date\n",
    "first_date = combined_data['date'].min()\n",
    "last_date = combined_data['date'].max()\n",
    "\n",
    "print(f\"First date in the dataset: {first_date}\")\n",
    "print(f\"Last date in the dataset: {last_date}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "60cc0905",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique IDs in the training dataset: 35100\n",
      "Number of unique IDs in the validation dataset: 11521\n",
      "Number of unique IDs in the test dataset: 11663\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Count the unique IDs in each dataset\n",
    "train_unique_ids_count = train_data_london['id'].nunique()\n",
    "valid_unique_ids_count = valid_data_london['id'].nunique()\n",
    "test_unique_ids_count = test_data_london['id'].nunique()\n",
    "\n",
    "# Display the count of unique IDs\n",
    "print(f\"Number of unique IDs in the training dataset: {train_unique_ids_count}\")\n",
    "print(f\"Number of unique IDs in the validation dataset: {valid_unique_ids_count}\")\n",
    "print(f\"Number of unique IDs in the test dataset: {test_unique_ids_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eec801b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First date in the training dataset: 2023-10-15 00:00:00\n",
      "Last date in the training dataset: 2024-01-13 00:00:00\n",
      "First date in the validation dataset: 2024-01-14 00:00:00\n",
      "Last date in the validation dataset: 2024-02-12 00:00:00\n",
      "First date in the test dataset: 2024-02-13 00:00:00\n",
      "Last date in the test dataset: 2024-03-12 00:00:00\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Ensure the 'date' column is in datetime format for each dataset\n",
    "train_data_london['date'] = pd.to_datetime(train_data_london['date'])\n",
    "valid_data_london['date'] = pd.to_datetime(valid_data_london['date'])\n",
    "test_data_london['date'] = pd.to_datetime(test_data_london['date'])\n",
    "\n",
    "# Get the first and last date for each dataset\n",
    "train_first_date = train_data_london['date'].min()\n",
    "train_last_date = train_data_london['date'].max()\n",
    "\n",
    "valid_first_date = valid_data_london['date'].min()\n",
    "valid_last_date = valid_data_london['date'].max()\n",
    "\n",
    "test_first_date = test_data_london['date'].min()\n",
    "test_last_date = test_data_london['date'].max()\n",
    "\n",
    "# Display the first and last date for each dataset\n",
    "print(f\"First date in the training dataset: {train_first_date}\")\n",
    "print(f\"Last date in the training dataset: {train_last_date}\")\n",
    "\n",
    "print(f\"First date in the validation dataset: {valid_first_date}\")\n",
    "print(f\"Last date in the validation dataset: {valid_last_date}\")\n",
    "\n",
    "print(f\"First date in the test dataset: {test_first_date}\")\n",
    "print(f\"Last date in the test dataset: {test_last_date}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f010848",
   "metadata": {},
   "source": [
    "# Engineering dataset for baseline models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cfaf9ffe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered Train Data Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 539702 entries, 4 to 3156839\n",
      "Columns: 146 entries, id to kitchen_amenities\n",
      "dtypes: bool(116), datetime64[ns](1), float64(10), int64(19)\n",
      "memory usage: 187.4 MB\n",
      "None\n",
      "Number of unique IDs in filtered train data: 6000\n",
      "\n",
      "Filtered Validation Data Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 58000 entries, 4 to 334005\n",
      "Columns: 146 entries, id to kitchen_amenities\n",
      "dtypes: bool(116), datetime64[ns](1), float64(10), int64(19)\n",
      "memory usage: 20.1 MB\n",
      "None\n",
      "Number of unique IDs in filtered validation data: 2000\n",
      "\n",
      "Filtered Test Data Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 57999 entries, 9 to 338145\n",
      "Columns: 146 entries, id to kitchen_amenities\n",
      "dtypes: bool(116), datetime64[ns](1), float64(10), int64(19)\n",
      "memory usage: 20.1 MB\n",
      "None\n",
      "Number of unique IDs in filtered test data: 2000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Set the random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Extract unique IDs from each dataset\n",
    "unique_train_ids = train_data_london['id'].unique()\n",
    "unique_valid_ids = valid_data_london['id'].unique()\n",
    "unique_test_ids = test_data_london['id'].unique()\n",
    "\n",
    "# Randomly select 6000 unique IDs for training, 2000 for validation, and 2000 for testing\n",
    "selected_train_ids = np.random.choice(unique_train_ids, 6000, replace=False)\n",
    "selected_valid_ids = np.random.choice(unique_valid_ids, 2000, replace=False)\n",
    "selected_test_ids = np.random.choice(unique_test_ids, 2000, replace=False)\n",
    "\n",
    "# Ensure IDs are exclusive to each dataset\n",
    "selected_train_ids = set(selected_train_ids)\n",
    "selected_valid_ids = set(selected_valid_ids)\n",
    "selected_test_ids = set(selected_test_ids)\n",
    "\n",
    "# Filter datasets based on the selected unique IDs\n",
    "train_data_london_filtered = train_data_london[train_data_london['id'].isin(selected_train_ids)]\n",
    "valid_data_london_filtered = valid_data_london[valid_data_london['id'].isin(selected_valid_ids)]\n",
    "test_data_london_filtered = test_data_london[test_data_london['id'].isin(selected_test_ids)]\n",
    "\n",
    "# Check the amount of unique IDs in the filtered datasets\n",
    "train_unique_count = len(train_data_london_filtered['id'].unique())\n",
    "valid_unique_count = len(valid_data_london_filtered['id'].unique())\n",
    "test_unique_count = len(test_data_london_filtered['id'].unique())\n",
    "\n",
    "# Display the result\n",
    "print(\"Filtered Train Data Info:\")\n",
    "print(train_data_london_filtered.info())\n",
    "print(f\"Number of unique IDs in filtered train data: {train_unique_count}\")\n",
    "\n",
    "print(\"\\nFiltered Validation Data Info:\")\n",
    "print(valid_data_london_filtered.info())\n",
    "print(f\"Number of unique IDs in filtered validation data: {valid_unique_count}\")\n",
    "\n",
    "print(\"\\nFiltered Test Data Info:\")\n",
    "print(test_data_london_filtered.info())\n",
    "print(f\"Number of unique IDs in filtered test data: {test_unique_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "39147289",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data: Unique days: 91, Start date: 2023-10-15 00:00:00, End date: 2024-01-13 00:00:00\n",
      "Validation Data: Unique days: 29, Start date: 2024-01-14 00:00:00, End date: 2024-02-11 00:00:00\n",
      "Test Data: Unique days: 29, Start date: 2024-02-13 00:00:00, End date: 2024-03-12 00:00:00\n",
      "\n",
      "No overlapping IDs between train and validation sets: True\n",
      "No overlapping IDs between train and test sets: True\n",
      "No overlapping IDs between validation and test sets: True\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Function to count the number of unique days and get the start and end dates in the dataset\n",
    "def analyze_dates(data):\n",
    "    unique_days = data['date'].nunique()\n",
    "    start_date = data['date'].min()\n",
    "    end_date = data['date'].max()\n",
    "    return unique_days, start_date, end_date\n",
    "\n",
    "# Analyze the dates in each dataset\n",
    "train_unique_days, train_start_date, train_end_date = analyze_dates(train_data_london_filtered)\n",
    "valid_unique_days, valid_start_date, valid_end_date = analyze_dates(valid_data_london_filtered)\n",
    "test_unique_days, test_start_date, test_end_date = analyze_dates(test_data_london_filtered)\n",
    "\n",
    "# Check for overlapping IDs\n",
    "train_ids = set(train_data_london_filtered['id'])\n",
    "valid_ids = set(valid_data_london_filtered['id'])\n",
    "test_ids = set(test_data_london_filtered['id'])\n",
    "\n",
    "no_overlap_train_valid = train_ids.isdisjoint(valid_ids)\n",
    "no_overlap_train_test = train_ids.isdisjoint(test_ids)\n",
    "no_overlap_valid_test = valid_ids.isdisjoint(test_ids)\n",
    "\n",
    "# Display the results\n",
    "print(f\"Train Data: Unique days: {train_unique_days}, Start date: {train_start_date}, End date: {train_end_date}\")\n",
    "print(f\"Validation Data: Unique days: {valid_unique_days}, Start date: {valid_start_date}, End date: {valid_end_date}\")\n",
    "print(f\"Test Data: Unique days: {test_unique_days}, Start date: {test_start_date}, End date: {test_end_date}\")\n",
    "\n",
    "print(f\"\\nNo overlapping IDs between train and validation sets: {no_overlap_train_valid}\")\n",
    "print(f\"No overlapping IDs between train and test sets: {no_overlap_train_test}\")\n",
    "print(f\"No overlapping IDs between validation and test sets: {no_overlap_valid_test}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eceae675",
   "metadata": {},
   "source": [
    "#### Data ready for LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104c1c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_london_filtered.to_csv('Train_model_London_Vince.csv', index=False)\n",
    "valid_data_london_filtered.to_csv('Valid_model_London_Vince.csv', index=False)\n",
    "test_data_london_filtered.to_csv('Test_model_London_Vince.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3857a37c",
   "metadata": {},
   "source": [
    "#### Reading in data with and without LSTM features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9ff32dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#insert file_path for the data\n",
    "file_path = 'C:/Users/anton/Documents/2de_master/Thesis/Code/analysis/Code/Airbnb_Spatiotemporal_Analysis/London Airbnb_Spatiotemporal_Analysis/Baseline models/Train_model_London_Vince.csv'\n",
    "#read data, and quickly check if it is correctly read in\n",
    "train_data_london_filtered= pd.read_csv(file_path)\n",
    "\n",
    "import pandas as pd\n",
    "#insert file_path for the data\n",
    "file_path = 'C:/Users/anton/Documents/2de_master/Thesis/Code/analysis/Code/Airbnb_Spatiotemporal_Analysis/London Airbnb_Spatiotemporal_Analysis/Baseline models/Valid_model_London_Vince.csv'\n",
    "#read data, and quickly check if it is correctly read in\n",
    "valid_data_london_filtered= pd.read_csv(file_path)\n",
    "\n",
    "import pandas as pd\n",
    "#insert file_path for the data\n",
    "file_path = 'C:/Users/anton/Documents/2de_master/Thesis/Code/analysis/Code/Airbnb_Spatiotemporal_Analysis/London Airbnb_Spatiotemporal_Analysis/Baseline models/Test_model_London_Vince.csv'\n",
    "#read data, and quickly check if it is correctly read in\n",
    "test_data_london_filtered= pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e003b6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#insert file_path for the data\n",
    "file_path = 'C:/Users/anton/Documents/2de_master/Thesis/Code/analysis/Code/Airbnb_Spatiotemporal_Analysis/London Airbnb_Spatiotemporal_Analysis/Baseline models/london met lstm/train_data_lstm_london_FINAL.csv'\n",
    "#read data, and quickly check if it is correctly read in\n",
    "train_data_lstm_london= pd.read_csv(file_path)\n",
    "\n",
    "import pandas as pd\n",
    "#insert file_path for the data\n",
    "file_path = 'C:/Users/anton/Documents/2de_master/Thesis/Code/analysis/Code/Airbnb_Spatiotemporal_Analysis/London Airbnb_Spatiotemporal_Analysis/Baseline models/london met lstm/val_data_lstm_london_FINAL.csv'\n",
    "#read data, and quickly check if it is correctly read in\n",
    "valid_data_lstm_london= pd.read_csv(file_path)\n",
    "\n",
    "import pandas as pd\n",
    "#insert file_path for the data\n",
    "file_path = 'C:/Users/anton/Documents/2de_master/Thesis/Code/analysis/Code/Airbnb_Spatiotemporal_Analysis/London Airbnb_Spatiotemporal_Analysis/Baseline models/london met lstm/test_data_lstm_london_FINAL.csv'\n",
    "#read data, and quickly check if it is correctly read in\n",
    "test_data_lstm_london= pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6b5e15a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    539702.000000\n",
       "mean        144.085108\n",
       "std         149.699791\n",
       "min           8.000000\n",
       "25%          59.000000\n",
       "50%          99.000000\n",
       "75%         173.000000\n",
       "max        1602.000000\n",
       "Name: price, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_london_filtered[\"price\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e7435b14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average standard deviation of price per ID is: 7.446580995160912\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Group the data by 'id'\n",
    "grouped = train_data_london_filtered.groupby('id')\n",
    "\n",
    "# Step 2: Calculate the standard deviation of 'price' for each 'id'\n",
    "std_per_id = grouped['price'].std()\n",
    "\n",
    "# Step 3: Calculate the average of these standard deviations\n",
    "average_std = std_per_id.mean()\n",
    "\n",
    "print(f\"The average standard deviation of price per ID is: {average_std}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abdb8d94",
   "metadata": {},
   "source": [
    "#### Selecting last days without the LSTM features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d9b850bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Percentage of unique IDs per split:\n",
      "Train: 60.00%\n",
      "Validation: 20.00%\n",
      "Test: 20.00%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Function to select the last day for each ID in the given dataframe\n",
    "def select_last_day_per_id(data):\n",
    "    data = data.sort_values(by=['id', 'date'])\n",
    "    last_day_data = data.groupby('id').tail(1)\n",
    "    return last_day_data\n",
    "\n",
    "# Apply the function to each split\n",
    "train_data_london_last_day = select_last_day_per_id(train_data_london_filtered)\n",
    "valid_data_london_last_day = select_last_day_per_id(valid_data_london_filtered)\n",
    "test_data_london_last_day = select_last_day_per_id(test_data_london_filtered)\n",
    "\n",
    "# Calculate the total unique IDs across all splits\n",
    "total_unique_ids = set(train_data_london_filtered['id']).union(valid_data_london_filtered['id']).union(test_data_london_filtered['id'])\n",
    "total_unique_count = len(total_unique_ids)\n",
    "\n",
    "# Calculate the percentage of unique IDs in each split based on the total unique IDs\n",
    "train_unique_count = len(set(train_data_london_last_day['id']))\n",
    "valid_unique_count = len(set(valid_data_london_last_day['id']))\n",
    "test_unique_count = len(set(test_data_london_last_day['id']))\n",
    "\n",
    "train_percentage = (train_unique_count / total_unique_count) * 100\n",
    "valid_percentage = (valid_unique_count / total_unique_count) * 100\n",
    "test_percentage = (test_unique_count / total_unique_count) * 100\n",
    "\n",
    "print(\"\\nPercentage of unique IDs per split:\")\n",
    "print(f\"Train: {train_percentage:.2f}%\")\n",
    "print(f\"Validation: {valid_percentage:.2f}%\")\n",
    "print(f\"Test: {test_percentage:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e5f2d618",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data: First date: 2023-12-28, Last date: 2024-01-13\n",
      "Validation Data: First date: 2024-02-11, Last date: 2024-02-11\n",
      "Test Data: First date: 2024-03-12, Last date: 2024-03-12\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Function to get the first and last date in the dataset\n",
    "def get_first_last_dates(data):\n",
    "    first_date = data['date'].min()\n",
    "    last_date = data['date'].max()\n",
    "    return first_date, last_date\n",
    "\n",
    "# Get the first and last date for each dataset\n",
    "train_first_date, train_last_date = get_first_last_dates(train_data_london_last_day)\n",
    "valid_first_date, valid_last_date = get_first_last_dates(valid_data_london_last_day)\n",
    "test_first_date, test_last_date = get_first_last_dates(test_data_london_last_day)\n",
    "\n",
    "# Display the results\n",
    "print(f\"Train Data: First date: {train_first_date}, Last date: {train_last_date}\")\n",
    "print(f\"Validation Data: First date: {valid_first_date}, Last date: {valid_last_date}\")\n",
    "print(f\"Test Data: First date: {test_first_date}, Last date: {test_last_date}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "147eeb1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 6000 entries, 534348 to 534421\n",
      "Columns: 146 entries, id to kitchen_amenities\n",
      "dtypes: bool(116), float64(10), int64(19), object(1)\n",
      "memory usage: 2.1+ MB\n"
     ]
    }
   ],
   "source": [
    "train_data_london_last_day.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c1b7a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_london_last_day.to_csv('Baslinemodels_train_london.csv', index=False)\n",
    "valid_data_london_last_day.to_csv('Baslinemodels_valid_london.csv', index=False)\n",
    "test_data_london_last_day.to_csv('Baslinemodels_test_london.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cdb1055",
   "metadata": {},
   "source": [
    "#### With the LSTM features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "388b3d5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overlapping IDs between train and validation sets: set()\n",
      "Number of overlapping IDs between train and validation sets: 0\n",
      "\n",
      "Overlapping IDs between train and test sets: set()\n",
      "Number of overlapping IDs between train and test sets: 0\n",
      "\n",
      "Overlapping IDs between validation and test sets: set()\n",
      "Number of overlapping IDs between validation and test sets: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Extracting unique IDs from each dataset\n",
    "train_ids = set(train_data_lstm_london['id'])\n",
    "valid_ids = set(valid_data_lstm_london['id'])\n",
    "test_ids = set(test_data_lstm_london['id'])\n",
    "\n",
    "# Check for overlapping IDs between the datasets\n",
    "train_valid_overlap = train_ids.intersection(valid_ids)\n",
    "train_test_overlap = train_ids.intersection(test_ids)\n",
    "valid_test_overlap = valid_ids.intersection(test_ids)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Overlapping IDs between train and validation sets: {train_valid_overlap}\")\n",
    "print(f\"Number of overlapping IDs between train and validation sets: {len(train_valid_overlap)}\\n\")\n",
    "\n",
    "print(f\"Overlapping IDs between train and test sets: {train_test_overlap}\")\n",
    "print(f\"Number of overlapping IDs between train and test sets: {len(train_test_overlap)}\\n\")\n",
    "\n",
    "print(f\"Overlapping IDs between validation and test sets: {valid_test_overlap}\")\n",
    "print(f\"Number of overlapping IDs between validation and test sets: {len(valid_test_overlap)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "25bbabb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged Train Data: First date: 2023-12-28, Last date: 2024-01-13\n",
      "Merged Validation Data: First date: 2024-02-11, Last date: 2024-02-11\n",
      "Merged Test Data: First date: 2024-03-12, Last date: 2024-03-12\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Function to get the first and last date in the dataset\n",
    "def get_first_last_dates(data):\n",
    "    first_date = data['date'].min()\n",
    "    last_date = data['date'].max()\n",
    "    return first_date, last_date\n",
    "\n",
    "# Get the first and last date for each dataset\n",
    "train_first_date, train_last_date = get_first_last_dates(train_data_lstm_london)\n",
    "valid_first_date, valid_last_date = get_first_last_dates(valid_data_lstm_london)\n",
    "test_first_date, test_last_date = get_first_last_dates(test_data_lstm_london)\n",
    "\n",
    "# Display the results\n",
    "print(f\"Merged Train Data: First date: {train_first_date}, Last date: {train_last_date}\")\n",
    "print(f\"Merged Validation Data: First date: {valid_first_date}, Last date: {valid_last_date}\")\n",
    "print(f\"Merged Test Data: First date: {test_first_date}, Last date: {test_last_date}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221dc26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_lstm_london.to_csv('Baslinemodels_train_lstm_london.csv', index=False)\n",
    "valid_data_lstm_london.to_csv('Baslinemodels_valid_lstm_london.csv', index=False)\n",
    "test_data_lstm_london.to_csv('Baslinemodels_test_lstm_london.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "422d322d",
   "metadata": {},
   "source": [
    "#### Check if original dataset and lstm dataset are identical except additional columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cf404e5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data in train_data_lstm_london (excluding the last 16 columns) is identical to train_data_london_last_day.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming the dataframes are already loaded\n",
    "\n",
    "# Get the list of columns to compare, excluding the last 16 columns from train_data_lstm_london\n",
    "columns_to_compare = train_data_lstm_london.columns[:-16]\n",
    "\n",
    "# Extract the relevant columns from train_data_lstm_london\n",
    "trimmed_train_data_lstm_london = train_data_lstm_london[columns_to_compare]\n",
    "\n",
    "# Align dataframes to ensure they have the same order of columns and index\n",
    "trimmed_train_data_lstm_london = trimmed_train_data_lstm_london.reset_index(drop=True)\n",
    "train_data_london_last_day = train_data_london_last_day[columns_to_compare].reset_index(drop=True)\n",
    "\n",
    "# Compare the dataframes\n",
    "differences = trimmed_train_data_lstm_london != train_data_london_last_day\n",
    "\n",
    "# Find the indices and columns where differences occur\n",
    "diff_indices = differences[differences].stack().index.tolist()\n",
    "\n",
    "if not diff_indices:\n",
    "    print(\"The data in train_data_lstm_london (excluding the last 16 columns) is identical to train_data_london_last_day.\")\n",
    "else:\n",
    "    print(\"Differences found:\")\n",
    "    for index, column in diff_indices:\n",
    "        lstm_value = trimmed_train_data_lstm_london.loc[index, column]\n",
    "        last_day_value = train_data_london_last_day.loc[index, column]\n",
    "        print(f\"Row {index}, Column '{column}': train_data_lstm_london = {lstm_value}, train_data_london_last_day = {last_day_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a01f46",
   "metadata": {},
   "source": [
    "# Baseline models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "78d7be31",
   "metadata": {},
   "outputs": [],
   "source": [
    "#WITHOUT LSTM\n",
    "import pandas as pd\n",
    "#insert file_path for the data\n",
    "file_path = 'C:/Users/anton/Documents/2de_master/Thesis/Code/analysis/Code/Airbnb_Spatiotemporal_Analysis/London Airbnb_Spatiotemporal_Analysis/Baseline models/Baslinemodels_train_london.csv'\n",
    "#read data, and quickly check if it is correctly read in\n",
    "train_data_london= pd.read_csv(file_path)\n",
    "\n",
    "import pandas as pd\n",
    "#insert file_path for the data\n",
    "file_path = 'C:/Users/anton/Documents/2de_master/Thesis/Code/analysis/Code/Airbnb_Spatiotemporal_Analysis/London Airbnb_Spatiotemporal_Analysis/Baseline models/Baslinemodels_valid_london.csv'\n",
    "#read data, and quickly check if it is correctly read in\n",
    "valid_data_london= pd.read_csv(file_path)\n",
    "\n",
    "import pandas as pd\n",
    "#insert file_path for the data\n",
    "file_path = 'C:/Users/anton/Documents/2de_master/Thesis/Code/analysis/Code/Airbnb_Spatiotemporal_Analysis/London Airbnb_Spatiotemporal_Analysis/Baseline models/Baslinemodels_test_london.csv'\n",
    "#read data, and quickly check if it is correctly read in\n",
    "test_data_london= pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1f64e34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#WITH LSTM\n",
    "import pandas as pd\n",
    "#insert file_path for the data\n",
    "file_path = 'C:/Users/anton/Documents/2de_master/Thesis/Code/analysis/Code/Airbnb_Spatiotemporal_Analysis/London Airbnb_Spatiotemporal_Analysis/Baseline models/Baslinemodels_train_lstm_london.csv'\n",
    "#read data, and quickly check if it is correctly read in\n",
    "train_data_lstm_london= pd.read_csv(file_path)\n",
    "\n",
    "import pandas as pd\n",
    "#insert file_path for the data\n",
    "file_path = 'C:/Users/anton/Documents/2de_master/Thesis/Code/analysis/Code/Airbnb_Spatiotemporal_Analysis/London Airbnb_Spatiotemporal_Analysis/Baseline models/Baslinemodels_valid_lstm_london.csv'\n",
    "#read data, and quickly check if it is correctly read in\n",
    "valid_data_lstm_london= pd.read_csv(file_path)\n",
    "\n",
    "import pandas as pd\n",
    "#insert file_path for the data\n",
    "file_path = 'C:/Users/anton/Documents/2de_master/Thesis/Code/analysis/Code/Airbnb_Spatiotemporal_Analysis/London Airbnb_Spatiotemporal_Analysis/Baseline models/Baslinemodels_test_lstm_london.csv'\n",
    "#read data, and quickly check if it is correctly read in\n",
    "test_data_lstm_london= pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bf66d4eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Columns: 146 entries, id to kitchen_amenities\n",
      "dtypes: bool(116), float64(10), int64(19), object(1)\n",
      "memory usage: 3.4+ MB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Concatenate the datasets\n",
    "combined_data = pd.concat([train_data_london, valid_data_london, test_data_london], ignore_index=True)\n",
    "\n",
    "# Display information about the combined dataset\n",
    "combined_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "219b7490",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6000 entries, 0 to 5999\n",
      "Columns: 162 entries, id to 15\n",
      "dtypes: bool(116), float64(26), int64(19), object(1)\n",
      "memory usage: 2.8+ MB\n"
     ]
    }
   ],
   "source": [
    "train_data_lstm_london.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4e424519",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data - Columns with NaN values and their counts:\n",
      "0     1\n",
      "1     1\n",
      "2     1\n",
      "3     1\n",
      "4     1\n",
      "5     1\n",
      "6     1\n",
      "7     1\n",
      "8     1\n",
      "9     1\n",
      "10    1\n",
      "11    1\n",
      "12    1\n",
      "13    1\n",
      "14    1\n",
      "15    1\n",
      "dtype: int64\n",
      "\n",
      "Valid Data - Columns with NaN values and their counts:\n",
      "Series([], dtype: int64)\n",
      "\n",
      "Test Data - Columns with NaN values and their counts:\n",
      "Series([], dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Check for NaN values in the train dataset\n",
    "train_nan_counts = train_data_lstm_london.isna().sum()\n",
    "train_columns_with_nan = train_nan_counts[train_nan_counts > 0]\n",
    "print(\"Train Data - Columns with NaN values and their counts:\")\n",
    "print(train_columns_with_nan)\n",
    "\n",
    "# Check for NaN values in the valid dataset\n",
    "valid_nan_counts = valid_data_lstm_london.isna().sum()\n",
    "valid_columns_with_nan = valid_nan_counts[valid_nan_counts > 0]\n",
    "print(\"\\nValid Data - Columns with NaN values and their counts:\")\n",
    "print(valid_columns_with_nan)\n",
    "\n",
    "# Check for NaN values in the test dataset\n",
    "test_nan_counts = test_data_lstm_london.isna().sum()\n",
    "test_columns_with_nan = test_nan_counts[test_nan_counts > 0]\n",
    "print(\"\\nTest Data - Columns with NaN values and their counts:\")\n",
    "print(test_columns_with_nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a6b8b082",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IDs are unique across the train, validation, and test datasets.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Extract IDs from each dataset\n",
    "train_ids = set(train_data_lstm_london['id'])\n",
    "valid_ids = set(valid_data_lstm_london['id'])\n",
    "test_ids = set(test_data_lstm_london['id'])\n",
    "\n",
    "# Check for overlapping IDs between the datasets\n",
    "overlap_train_valid = train_ids.intersection(valid_ids)\n",
    "overlap_train_test = train_ids.intersection(test_ids)\n",
    "overlap_valid_test = valid_ids.intersection(test_ids)\n",
    "\n",
    "# Output the results\n",
    "if not overlap_train_valid and not overlap_train_test and not overlap_valid_test:\n",
    "    print(\"IDs are unique across the train, validation, and test datasets.\")\n",
    "else:\n",
    "    print(\"There are overlapping IDs between the datasets.\")\n",
    "    if overlap_train_valid:\n",
    "        print(f\"Overlapping IDs between train and validation datasets: {overlap_train_valid}\")\n",
    "    if overlap_train_test:\n",
    "        print(f\"Overlapping IDs between train and test datasets: {overlap_train_test}\")\n",
    "    if overlap_valid_test:\n",
    "        print(f\"Overlapping IDs between validation and test datasets: {overlap_valid_test}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "358e0070",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6000 entries, 0 to 5999\n",
      "Columns: 162 entries, id to 15\n",
      "dtypes: bool(116), float64(26), int64(19), object(1)\n",
      "memory usage: 2.8+ MB\n"
     ]
    }
   ],
   "source": [
    "train_data_lstm_london.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "06a3aeed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of all columns in the dataset:\n",
      "['id', 'date', 'available', 'price', 'season_Autumn', 'is_holiday', 'is_school_holiday', 'host_id', 'host_response_time', 'host_is_superhost', 'host_listings_count', 'host_total_listings_count', 'host_identity_verified', 'latitude', 'longitude', 'accommodates', 'bathrooms', 'bedrooms', 'beds', 'availability_90', 'availability_365', 'number_of_reviews', 'number_of_reviews_ltm', 'number_of_reviews_l30d', 'review_scores_rating', 'instant_bookable', 'calculated_host_listings_count', 'calculated_host_listings_count_entire_homes', 'calculated_host_listings_count_private_rooms', 'reviews_per_month', 'conditioner', 'broadcast', 'tv', 'Central heating', 'game console', 'Extra pillows and blankets', 'view', 'Bathtub', 'Private patio or balcony', 'coffee', 'Luggage dropoff allowed', 'oven', 'Toaster', 'Essentials', 'Fire extinguisher', 'toys children', 'Hair dryer', 'Washer', 'Long term stays allowed', 'Shower gel', 'backyard', 'Hangers', 'soap', 'bbq', 'Portable fans', 'Dryer', 'stove', 'Lockbox', 'Free washer – In unit', 'Kitchen', 'Outdoor dining area', 'Iron', 'Laundromat nearby', 'shampoo', 'sauna', 'Wine glasses', 'sound system', 'Freezer', 'Room-darkening shades', 'Hot water kettle', 'Host greets you', 'gym', 'Heating', 'Lock on bedroom door', 'Books and reading material', 'exercise equipment', 'Security cameras on property', 'hot tub', 'wifi', 'pool', 'Hot water', 'Drying rack for clothing', 'Elevator', 'clothing storage', 'crib', 'Private entrance', 'Bed linens', 'First aid kit', 'Microwave', 'Pets allowed', 'Dedicated workspace', 'parking', 'Self check-in', 'Outdoor furniture', 'Dining table', 'Cleaning products', 'Carbon monoxide alarm', 'Dishwasher', 'Smoke alarm', 'total_amenities', 'listing_reviewed', 'neighbourhood_Barking and Dagenham', 'neighbourhood_Barnet', 'neighbourhood_Bexley', 'neighbourhood_Brent', 'neighbourhood_Bromley', 'neighbourhood_Camden', 'neighbourhood_City of London', 'neighbourhood_Croydon', 'neighbourhood_Ealing', 'neighbourhood_Enfield', 'neighbourhood_Greenwich', 'neighbourhood_Hackney', 'neighbourhood_Hammersmith and Fulham', 'neighbourhood_Haringey', 'neighbourhood_Harrow', 'neighbourhood_Havering', 'neighbourhood_Hillingdon', 'neighbourhood_Hounslow', 'neighbourhood_Islington', 'neighbourhood_Kensington and Chelsea', 'neighbourhood_Kingston upon Thames', 'neighbourhood_Lambeth', 'neighbourhood_Lewisham', 'neighbourhood_Merton', 'neighbourhood_Newham', 'neighbourhood_Redbridge', 'neighbourhood_Richmond upon Thames', 'neighbourhood_Southwark', 'neighbourhood_Sutton', 'neighbourhood_Tower Hamlets', 'neighbourhood_Waltham Forest', 'neighbourhood_Wandsworth', 'neighbourhood_Westminster', 'property_type_Apartment', 'property_type_Hotel', 'property_type_House', 'property_type_Other', 'room_type_Entire home/apt', 'room_type_Private room', 'nearby_airbnbs_count', 'luxury_amenities_score', 'nearby_restaurants_bars', 'nearby_transport', 'mean_price_neighbors', 'kitchen_amenities', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15']\n"
     ]
    }
   ],
   "source": [
    "# Print a list of all columns in the dataset\n",
    "columns_list = train_data_lstm_london.columns.tolist()\n",
    "print(\"List of all columns in the dataset:\")\n",
    "print(columns_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "aa037cbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First date in the LSTM training dataset (london): 2023-12-28 00:00:00\n",
      "Last date in the LSTM training dataset (london): 2024-01-13 00:00:00\n",
      "First date in the LSTM validation dataset (london): 2024-02-11 00:00:00\n",
      "Last date in the LSTM validation dataset (london): 2024-02-11 00:00:00\n",
      "First date in the LSTM test dataset (london): 2024-03-12 00:00:00\n",
      "Last date in the LSTM test dataset (london): 2024-03-12 00:00:00\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Ensure the 'date' column is in datetime format for each dataset\n",
    "train_data_lstm_london['date'] = pd.to_datetime(train_data_lstm_london['date'])\n",
    "valid_data_lstm_london['date'] = pd.to_datetime(valid_data_lstm_london['date'])\n",
    "test_data_lstm_london['date'] = pd.to_datetime(test_data_lstm_london['date'])\n",
    "\n",
    "# Get the first and last date for each dataset\n",
    "train_lstm_first_date = train_data_lstm_london['date'].min()\n",
    "train_lstm_last_date = train_data_lstm_london['date'].max()\n",
    "\n",
    "valid_lstm_first_date = valid_data_lstm_london['date'].min()\n",
    "valid_lstm_last_date = valid_data_lstm_london['date'].max()\n",
    "\n",
    "test_lstm_first_date = test_data_lstm_london['date'].min()\n",
    "test_lstm_last_date = test_data_lstm_london['date'].max()\n",
    "\n",
    "# Display the first and last date for each dataset\n",
    "print(f\"First date in the LSTM training dataset (london): {train_lstm_first_date}\")\n",
    "print(f\"Last date in the LSTM training dataset (london): {train_lstm_last_date}\")\n",
    "\n",
    "print(f\"First date in the LSTM validation dataset (london): {valid_lstm_first_date}\")\n",
    "print(f\"Last date in the LSTM validation dataset (london): {valid_lstm_last_date}\")\n",
    "\n",
    "print(f\"First date in the LSTM test dataset (london): {test_lstm_first_date}\")\n",
    "print(f\"Last date in the LSTM test dataset (london): {test_lstm_last_date}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0d2860fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First date in the training dataset (london): 2023-12-28 00:00:00\n",
      "Last date in the training dataset (london): 2024-01-13 00:00:00\n",
      "First date in the validation dataset (london): 2024-02-11 00:00:00\n",
      "Last date in the validation dataset (london): 2024-02-11 00:00:00\n",
      "First date in the test dataset (london): 2024-03-12 00:00:00\n",
      "Last date in the test dataset (london): 2024-03-12 00:00:00\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Ensure the 'date' column is in datetime format for each dataset\n",
    "train_data_london['date'] = pd.to_datetime(train_data_london['date'])\n",
    "valid_data_london['date'] = pd.to_datetime(valid_data_london['date'])\n",
    "test_data_london['date'] = pd.to_datetime(test_data_london['date'])\n",
    "\n",
    "# Get the first and last date for each dataset\n",
    "train_london_first_date = train_data_london['date'].min()\n",
    "train_london_last_date = train_data_london['date'].max()\n",
    "\n",
    "valid_london_first_date = valid_data_london['date'].min()\n",
    "valid_london_last_date = valid_data_london['date'].max()\n",
    "\n",
    "test_london_first_date = test_data_london['date'].min()\n",
    "test_london_last_date = test_data_london['date'].max()\n",
    "\n",
    "# Display the first and last date for each dataset\n",
    "print(f\"First date in the training dataset (london): {train_london_first_date}\")\n",
    "print(f\"Last date in the training dataset (london): {train_london_last_date}\")\n",
    "\n",
    "print(f\"First date in the validation dataset (london): {valid_london_first_date}\")\n",
    "print(f\"Last date in the validation dataset (london): {valid_london_last_date}\")\n",
    "\n",
    "print(f\"First date in the test dataset (london): {test_london_first_date}\")\n",
    "print(f\"Last date in the test dataset (london): {test_london_last_date}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6271d932",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing values in Train Data:\n",
      "Series([], dtype: int64)\n",
      "\n",
      "Missing values in Validation Data:\n",
      "Series([], dtype: int64)\n",
      "\n",
      "Missing values in Test Data:\n",
      "Series([], dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# List of datasets to check\n",
    "datasets = {\n",
    "    \"Train Data\": train_data_lstm_london,\n",
    "    \"Validation Data\": valid_data_lstm_london,\n",
    "    \"Test Data\": test_data_lstm_london\n",
    "}\n",
    "\n",
    "# Loop through each dataset and print the number of missing values per column\n",
    "for dataset_name, dataset in datasets.items():\n",
    "    print(f\"\\nMissing values in {dataset_name}:\")\n",
    "    missing_values_count = dataset.isnull().sum()\n",
    "    print(missing_values_count[missing_values_count > 0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "031f6404",
   "metadata": {},
   "source": [
    "## XGB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "459c38c0",
   "metadata": {},
   "source": [
    "## Without LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea390cd",
   "metadata": {},
   "source": [
    "#### Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "867f4afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "\n",
    "# Excluded columns for scaling\n",
    "excluded_columns = ['id', 'host_id', 'longitude', 'latitude', 'date']\n",
    "\n",
    "# Prepare the data by dropping unnecessary columns and separating features and target\n",
    "def prepare_data(data, target_column):\n",
    "    X = data.drop(columns=['id', 'host_id', 'date', target_column])\n",
    "    y = data[target_column]\n",
    "    return X, y\n",
    "\n",
    "# Scale the features and the target variable\n",
    "def scale_features_and_target(X, y, excluded_columns):\n",
    "    numerical_features = X.select_dtypes(include=['float64', 'int64']).columns.difference(excluded_columns)\n",
    "    scaler = RobustScaler()\n",
    "    X_scaled = X.copy()\n",
    "    X_scaled[numerical_features] = scaler.fit_transform(X[numerical_features])\n",
    "    y_scaled = scaler.fit_transform(y.values.reshape(-1, 1)).flatten()\n",
    "    return X_scaled, y_scaled, scaler\n",
    "\n",
    "# Prepare the training, validation, and test sets\n",
    "X_train_raw, y_train_raw = prepare_data(train_data_london, 'price')\n",
    "X_valid_raw, y_valid_raw = prepare_data(valid_data_london, 'price')\n",
    "X_test_raw, y_test_raw = prepare_data(test_data_london, 'price')\n",
    "\n",
    "# Apply scaling to both features and target\n",
    "X_train, y_train, scaler = scale_features_and_target(X_train_raw, y_train_raw, excluded_columns)\n",
    "X_valid, y_valid, _ = scale_features_and_target(X_valid_raw, y_valid_raw, excluded_columns)\n",
    "X_test, y_test, _ = scale_features_and_target(X_test_raw, y_test_raw, excluded_columns)\n",
    "\n",
    "# Save the scaler\n",
    "with open('scaler_without_LSTM.pkl', 'wb') as f:\n",
    "    pickle.dump(scaler, f)\n",
    "\n",
    "# Save the scaled datasets\n",
    "scaled_train_df = pd.DataFrame(X_train, columns=X_train_raw.columns)\n",
    "scaled_train_df['price'] = y_train\n",
    "scaled_valid_df = pd.DataFrame(X_valid, columns=X_valid_raw.columns)\n",
    "scaled_valid_df['price'] = y_valid\n",
    "scaled_test_df = pd.DataFrame(X_test, columns=X_test_raw.columns)\n",
    "scaled_test_df['price'] = y_test\n",
    "\n",
    "scaled_train_df.to_csv('scaled_train_data_without_LSTM.csv', index=False)\n",
    "scaled_valid_df.to_csv('scaled_valid_data_without_LSTM.csv', index=False)\n",
    "scaled_test_df.to_csv('scaled_test_data_without_LSTM.csv', index=False)\n",
    "\n",
    "# Function to optimize using Optuna\n",
    "def objective(trial):\n",
    "    param = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 1000),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
    "        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "        'gamma': trial.suggest_float('gamma', 0, 5),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 0, 10),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 0, 10)\n",
    "    }\n",
    "\n",
    "    model = XGBRegressor(\n",
    "        objective='reg:squarederror',\n",
    "        eval_metric='rmse',\n",
    "        **param\n",
    "    )\n",
    "    \n",
    "    model.fit(X_train, y_train, eval_set=[(X_valid, y_valid)], verbose=False)\n",
    "    preds = model.predict(X_valid)\n",
    "    mse = mean_squared_error(y_valid, preds)\n",
    "    rmse = np.sqrt(mse)\n",
    "    return rmse\n",
    "\n",
    "# Create a study\n",
    "study = optuna.create_study(direction='minimize', sampler=TPESampler())\n",
    "study.optimize(objective, n_trials=50, show_progress_bar=True)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params = study.best_params\n",
    "print(\"Best hyperparameters: \", best_params)\n",
    "\n",
    "# Train the model with the best hyperparameters\n",
    "best_model = XGBRegressor(\n",
    "    objective='reg:squarederror',\n",
    "    eval_metric='rmse',\n",
    "    **best_params\n",
    ")\n",
    "\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the training, validation, and test sets with the best model\n",
    "y_train_pred_scaled = best_model.predict(X_train)\n",
    "y_valid_pred_scaled = best_model.predict(X_valid)\n",
    "y_test_pred_scaled = best_model.predict(X_test)\n",
    "\n",
    "# Inverse transform the scaled predictions and actual target values\n",
    "y_train_pred = scaler.inverse_transform(y_train_pred_scaled.reshape(-1, 1)).flatten()\n",
    "y_valid_pred = scaler.inverse_transform(y_valid_pred_scaled.reshape(-1, 1)).flatten()\n",
    "y_test_pred = scaler.inverse_transform(y_test_pred_scaled.reshape(-1, 1)).flatten()\n",
    "y_train_orig = scaler.inverse_transform(y_train.reshape(-1, 1)).flatten()\n",
    "y_valid_orig = scaler.inverse_transform(y_valid.reshape(-1, 1)).flatten()\n",
    "y_test_orig = scaler.inverse_transform(y_test.reshape(-1, 1)).flatten()\n",
    "\n",
    "# Calculate performance metrics on the original scale\n",
    "def print_metrics(y_true, y_pred, dataset_name):\n",
    "    print(f\"{dataset_name} Performance Metrics:\")\n",
    "    print(\"Mean Absolute Error (MAE): \", mean_absolute_error(y_true, y_pred))\n",
    "    print(\"Mean Squared Error (MSE): \", mean_squared_error(y_true, y_pred))\n",
    "    print(\"R-squared (R2): \", r2_score(y_true, y_pred))\n",
    "    print()\n",
    "\n",
    "# Print metrics for training, validation, and test data\n",
    "print(\"Performance with tuned hyperparameters:\")\n",
    "print_metrics(y_train_orig, y_train_pred, \"Training\")\n",
    "print_metrics(y_valid_orig, y_valid_pred, \"Validation\")\n",
    "print_metrics(y_test_orig, y_test_pred, \"Test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0b6b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the model\n",
    "joblib.dump(best_model, 'xgb_model_without_lstm_london.joblib')\n",
    "\n",
    "# Load the model\n",
    "loaded_model = joblib.load('xgb_model_without_lstm_london.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d9463a3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance with loaded model:\n",
      "Training Performance Metrics:\n",
      "Mean Absolute Error (MAE):  23.060624954223634\n",
      "Mean Squared Error (MSE):  1336.8137632134117\n",
      "R-squared (R2):  0.9345619451347364\n",
      "\n",
      "Validation Performance Metrics:\n",
      "Mean Absolute Error (MAE):  51.91438133128773\n",
      "Mean Squared Error (MSE):  9692.381756454664\n",
      "R-squared (R2):  0.5441872014914553\n",
      "\n",
      "Test Performance Metrics:\n",
      "Mean Absolute Error (MAE):  53.07950595855713\n",
      "Mean Squared Error (MSE):  12451.532573815577\n",
      "R-squared (R2):  0.5175806634476922\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Step 1: Load the scaled datasets\n",
    "scaled_train_df = pd.read_csv('scaled_train_data_without_LSTM.csv')\n",
    "scaled_valid_df = pd.read_csv('scaled_valid_data_without_LSTM.csv')\n",
    "scaled_test_df = pd.read_csv('scaled_test_data_without_LSTM.csv')\n",
    "\n",
    "# Separate features and target from the scaled datasets\n",
    "X_train = scaled_train_df.drop(columns=['price'])\n",
    "y_train = scaled_train_df['price']\n",
    "X_valid = scaled_valid_df.drop(columns=['price'])\n",
    "y_valid = scaled_valid_df['price']\n",
    "X_test = scaled_test_df.drop(columns=['price'])\n",
    "y_test = scaled_test_df['price']\n",
    "\n",
    "# Step 2: Load the scaler\n",
    "scaler = joblib.load('scaler_without_LSTM.pkl')\n",
    "\n",
    "# Step 3: Load the saved model\n",
    "loaded_model = joblib.load('xgb_model_without_lstm_london.joblib')\n",
    "\n",
    "# Step 4: Make predictions using the loaded model\n",
    "y_train_pred_scaled = loaded_model.predict(X_train)\n",
    "y_valid_pred_scaled = loaded_model.predict(X_valid)\n",
    "y_test_pred_scaled = loaded_model.predict(X_test)\n",
    "\n",
    "# Step 5: Inverse transform the scaled predictions and actual target values\n",
    "y_train_pred = scaler.inverse_transform(y_train_pred_scaled.reshape(-1, 1)).flatten()\n",
    "y_valid_pred = scaler.inverse_transform(y_valid_pred_scaled.reshape(-1, 1)).flatten()\n",
    "y_test_pred = scaler.inverse_transform(y_test_pred_scaled.reshape(-1, 1)).flatten()\n",
    "y_train_orig = scaler.inverse_transform(y_train.values.reshape(-1, 1)).flatten()\n",
    "y_valid_orig = scaler.inverse_transform(y_valid.values.reshape(-1, 1)).flatten()\n",
    "y_test_orig = scaler.inverse_transform(y_test.values.reshape(-1, 1)).flatten()\n",
    "\n",
    "# Step 6: Calculate and print performance metrics on the original scale\n",
    "def print_metrics(y_true, y_pred, dataset_name):\n",
    "    print(f\"{dataset_name} Performance Metrics:\")\n",
    "    print(\"Mean Absolute Error (MAE): \", mean_absolute_error(y_true, y_pred))\n",
    "    print(\"Mean Squared Error (MSE): \", mean_squared_error(y_true, y_pred))\n",
    "    print(\"R-squared (R2): \", r2_score(y_true, y_pred))\n",
    "    print()\n",
    "\n",
    "# Print metrics for training, validation, and test data\n",
    "print(\"Performance with loaded model:\")\n",
    "print_metrics(y_train_orig, y_train_pred, \"Training\")\n",
    "print_metrics(y_valid_orig, y_valid_pred, \"Validation\")\n",
    "print_metrics(y_test_orig, y_test_pred, \"Test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a8ec9e2",
   "metadata": {},
   "source": [
    "## With LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51eb980a",
   "metadata": {},
   "source": [
    "#### hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca3cd67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "\n",
    "# Excluded columns for scaling\n",
    "excluded_columns = ['id', 'host_id', 'longitude', 'latitude', 'date']\n",
    "\n",
    "# Prepare the data by separating features and target\n",
    "def prepare_data(data, target_column):\n",
    "    X = data.drop(columns=['id', 'host_id', 'date', target_column])\n",
    "    y = data[target_column]\n",
    "    return X, y\n",
    "\n",
    "# Scale the features and the target variable\n",
    "def scale_features_and_target(X, y, excluded_columns):\n",
    "    numerical_features = X.select_dtypes(include=['float64', 'int64']).columns.difference(excluded_columns)\n",
    "    scaler = RobustScaler()\n",
    "    X_scaled = X.copy()\n",
    "    X_scaled[numerical_features] = scaler.fit_transform(X[numerical_features])\n",
    "    y_scaled = scaler.fit_transform(y.values.reshape(-1, 1)).flatten()\n",
    "    return X_scaled, y_scaled, scaler\n",
    "\n",
    "# Prepare the training, validation, and test sets for LSTM data\n",
    "X_train_raw, y_train_raw = prepare_data(train_data_lstm_london, 'price')\n",
    "X_valid_raw, y_valid_raw = prepare_data(valid_data_lstm_london, 'price')\n",
    "X_test_raw, y_test_raw = prepare_data(test_data_lstm_london, 'price')\n",
    "\n",
    "# Apply scaling to both features and target\n",
    "X_train_scaled, y_train_scaled, scaler = scale_features_and_target(X_train_raw, y_train_raw, excluded_columns)\n",
    "X_valid_scaled, y_valid_scaled, _ = scale_features_and_target(X_valid_raw, y_valid_raw, excluded_columns)\n",
    "X_test_scaled, y_test_scaled, _ = scale_features_and_target(X_test_raw, y_test_raw, excluded_columns)\n",
    "\n",
    "# Save the scaler\n",
    "with open('scaler_with_LSTM.pkl', 'wb') as f:\n",
    "    pickle.dump(scaler, f)\n",
    "\n",
    "# Save the scaled datasets\n",
    "scaled_train_df = pd.DataFrame(X_train_scaled, columns=X_train_raw.columns)\n",
    "scaled_train_df['price'] = y_train_scaled\n",
    "scaled_valid_df = pd.DataFrame(X_valid_scaled, columns=X_valid_raw.columns)\n",
    "scaled_valid_df['price'] = y_valid_scaled\n",
    "scaled_test_df = pd.DataFrame(X_test_scaled, columns=X_test_raw.columns)\n",
    "scaled_test_df['price'] = y_test_scaled\n",
    "\n",
    "scaled_train_df.to_csv('scaled_train_data_with_LSTM.csv', index=False)\n",
    "scaled_valid_df.to_csv('scaled_valid_data_with_LSTM.csv', index=False)\n",
    "scaled_test_df.to_csv('scaled_test_data_with_LSTM.csv', index=False)\n",
    "\n",
    "# Function to optimize using Optuna\n",
    "def objective(trial):\n",
    "    param = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 1000),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
    "        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "        'gamma': trial.suggest_float('gamma', 0, 5),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 0, 10),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 0, 10)\n",
    "    }\n",
    "\n",
    "    model = XGBRegressor(\n",
    "        objective='reg:squarederror',\n",
    "        eval_metric='rmse',  # Use rmse for evaluation\n",
    "        **param\n",
    "    )\n",
    "    \n",
    "    model.fit(X_train_scaled, y_train_scaled, eval_set=[(X_valid_scaled, y_valid_scaled)], verbose=False)\n",
    "    preds = model.predict(X_valid_scaled)\n",
    "    mse = mean_squared_error(y_valid_scaled, preds)\n",
    "    rmse = np.sqrt(mse)\n",
    "    return rmse\n",
    "\n",
    "# Create a study\n",
    "study = optuna.create_study(direction='minimize', sampler=TPESampler())\n",
    "study.optimize(objective, n_trials=50, show_progress_bar=True)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params = study.best_params\n",
    "print(\"Best hyperparameters: \", best_params)\n",
    "\n",
    "# Train the model with the best hyperparameters\n",
    "best_model = XGBRegressor(\n",
    "    objective='reg:squarederror',\n",
    "    eval_metric='rmse',  # Use rmse for evaluation\n",
    "    **best_params\n",
    ")\n",
    "\n",
    "best_model.fit(X_train_scaled, y_train_scaled)\n",
    "\n",
    "# Predict on the training, validation, and test sets with the best model\n",
    "y_train_pred_scaled = best_model.predict(X_train_scaled)\n",
    "y_valid_pred_scaled = best_model.predict(X_valid_scaled)\n",
    "y_test_pred_scaled = best_model.predict(X_test_scaled)\n",
    "\n",
    "# Inverse transform the scaled predictions and actual target values\n",
    "y_train_pred = scaler.inverse_transform(y_train_pred_scaled.reshape(-1, 1)).flatten()\n",
    "y_valid_pred = scaler.inverse_transform(y_valid_pred_scaled.reshape(-1, 1)).flatten()\n",
    "y_test_pred = scaler.inverse_transform(y_test_pred_scaled.reshape(-1, 1)).flatten()\n",
    "y_train_orig = scaler.inverse_transform(y_train_scaled.reshape(-1, 1)).flatten()\n",
    "y_valid_orig = scaler.inverse_transform(y_valid_scaled.reshape(-1, 1)).flatten()\n",
    "y_test_orig = scaler.inverse_transform(y_test_scaled.reshape(-1, 1)).flatten()\n",
    "\n",
    "# Calculate performance metrics on the original scale\n",
    "def print_metrics(y_true, y_pred, dataset_name):\n",
    "    print(f\"{dataset_name} Performance Metrics:\")\n",
    "    print(\"Mean Absolute Error (MAE): \", mean_absolute_error(y_true, y_pred))\n",
    "    print(\"Mean Squared Error (MSE): \", mean_squared_error(y_true, y_pred))\n",
    "    print(\"R-squared (R2): \", r2_score(y_true, y_pred))\n",
    "    print()\n",
    "\n",
    "# Print metrics for training, validation, and test data\n",
    "print(\"Performance with original scale:\")\n",
    "print_metrics(y_train_orig, y_train_pred, \"Training\")\n",
    "print_metrics(y_valid_orig, y_valid_pred, \"Validation\")\n",
    "print_metrics(y_test_orig, y_test_pred, \"Test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f6d725d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the model\n",
    "joblib.dump(best_model, 'xgb_model_with_lstm_london.joblib')\n",
    "\n",
    "# Load the model\n",
    "loaded_model = joblib.load('xgb_model_with_lstm_london.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4cfc59c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance with loaded model:\n",
      "Training Performance Metrics:\n",
      "Mean Absolute Error (MAE):  6.584342959722413\n",
      "Mean Squared Error (MSE):  357.0015648719301\n",
      "R-squared (R2):  0.9822412179248973\n",
      "\n",
      "Validation Performance Metrics:\n",
      "Mean Absolute Error (MAE):  5.701124455538664\n",
      "Mean Squared Error (MSE):  300.23208538087727\n",
      "R-squared (R2):  0.9858192469499272\n",
      "\n",
      "Test Performance Metrics:\n",
      "Mean Absolute Error (MAE):  19.128304667964834\n",
      "Mean Squared Error (MSE):  2114.5461566956715\n",
      "R-squared (R2):  0.9177179212821226\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Step 1: Load the scaled datasets\n",
    "scaled_train_df = pd.read_csv('scaled_train_data_with_LSTM.csv')\n",
    "scaled_valid_df = pd.read_csv('scaled_valid_data_with_LSTM.csv')\n",
    "scaled_test_df = pd.read_csv('scaled_test_data_with_LSTM.csv')\n",
    "\n",
    "# Separate features and target from the scaled datasets\n",
    "X_train = scaled_train_df.drop(columns=['price'])\n",
    "y_train = scaled_train_df['price']\n",
    "X_valid = scaled_valid_df.drop(columns=['price'])\n",
    "y_valid = scaled_valid_df['price']\n",
    "X_test = scaled_test_df.drop(columns=['price'])\n",
    "y_test = scaled_test_df['price']\n",
    "\n",
    "# Step 2: Load the scaler\n",
    "scaler = joblib.load('scaler_with_LSTM.pkl')\n",
    "\n",
    "# Step 3: Load the saved model\n",
    "loaded_model = joblib.load('xgb_model_with_lstm_london.joblib')\n",
    "\n",
    "# Step 4: Make predictions using the loaded model\n",
    "y_train_pred_scaled = loaded_model.predict(X_train)\n",
    "y_valid_pred_scaled = loaded_model.predict(X_valid)\n",
    "y_test_pred_scaled = loaded_model.predict(X_test)\n",
    "\n",
    "# Step 5: Inverse transform the scaled predictions and actual target values\n",
    "y_train_pred = scaler.inverse_transform(y_train_pred_scaled.reshape(-1, 1)).flatten()\n",
    "y_valid_pred = scaler.inverse_transform(y_valid_pred_scaled.reshape(-1, 1)).flatten()\n",
    "y_test_pred = scaler.inverse_transform(y_test_pred_scaled.reshape(-1, 1)).flatten()\n",
    "y_train_orig = scaler.inverse_transform(y_train.values.reshape(-1, 1)).flatten()\n",
    "y_valid_orig = scaler.inverse_transform(y_valid.values.reshape(-1, 1)).flatten()\n",
    "y_test_orig = scaler.inverse_transform(y_test.values.reshape(-1, 1)).flatten()\n",
    "\n",
    "# Step 6: Calculate and print performance metrics on the original scale\n",
    "def print_metrics(y_true, y_pred, dataset_name):\n",
    "    print(f\"{dataset_name} Performance Metrics:\")\n",
    "    print(\"Mean Absolute Error (MAE): \", mean_absolute_error(y_true, y_pred))\n",
    "    print(\"Mean Squared Error (MSE): \", mean_squared_error(y_true, y_pred))\n",
    "    print(\"R-squared (R2): \", r2_score(y_true, y_pred))\n",
    "    print()\n",
    "\n",
    "# Print metrics for training, validation, and test data\n",
    "print(\"Performance with loaded model:\")\n",
    "print_metrics(y_train_orig, y_train_pred, \"Training\")\n",
    "print_metrics(y_valid_orig, y_valid_pred, \"Validation\")\n",
    "print_metrics(y_test_orig, y_test_pred, \"Test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1948251",
   "metadata": {},
   "source": [
    "## RF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c38a99",
   "metadata": {},
   "source": [
    "## Without LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce82fca7",
   "metadata": {},
   "source": [
    "#### Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3fc0c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Excluded columns for scaling\n",
    "excluded_columns = ['id', 'host_id', 'longitude', 'latitude', 'date']\n",
    "\n",
    "# Prepare the data by dropping the unnecessary columns and separating features and target\n",
    "def prepare_data(data, target_column):\n",
    "    X = data.drop(columns=['id', 'host_id', 'date', target_column])\n",
    "    y = data[target_column]\n",
    "    return X, y\n",
    "\n",
    "# Scale the features and the target variable\n",
    "def scale_features_and_target(X, y, excluded_columns):\n",
    "    numerical_features = X.select_dtypes(include=['float64', 'int64']).columns.difference(excluded_columns)\n",
    "    scaler = RobustScaler()\n",
    "    X_scaled = X.copy()\n",
    "    X_scaled[numerical_features] = scaler.fit_transform(X[numerical_features])\n",
    "    y_scaled = scaler.fit_transform(y.values.reshape(-1, 1)).flatten()\n",
    "    return X_scaled, y_scaled, scaler\n",
    "\n",
    "# Prepare the training, validation, and test sets\n",
    "X_train_raw, y_train_raw = prepare_data(train_data_london, 'price')\n",
    "X_valid_raw, y_valid_raw = prepare_data(valid_data_london, 'price')\n",
    "X_test_raw, y_test_raw = prepare_data(test_data_london, 'price')\n",
    "\n",
    "# Apply scaling to both features and target\n",
    "X_train, y_train, scaler = scale_features_and_target(X_train_raw, y_train_raw, excluded_columns)\n",
    "X_valid, y_valid, _ = scale_features_and_target(X_valid_raw, y_valid_raw, excluded_columns)\n",
    "X_test, y_test, _ = scale_features_and_target(X_test_raw, y_test_raw, excluded_columns)\n",
    "\n",
    "# Function to optimize using Optuna\n",
    "def objective(trial):\n",
    "    param = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 500),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 15),\n",
    "        'min_samples_split': trial.suggest_int('min_samples_split', 5, 15),\n",
    "        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 5, 15),\n",
    "        'max_features': trial.suggest_categorical('max_features', [None, 'sqrt', 'log2'])\n",
    "    }\n",
    "\n",
    "    model = RandomForestRegressor(**param)\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_valid)\n",
    "    mse = mean_squared_error(y_valid, preds)\n",
    "    return mse\n",
    "\n",
    "# Create a study\n",
    "study = optuna.create_study(direction='minimize', sampler=TPESampler())\n",
    "study.optimize(objective, n_trials=50, show_progress_bar=True)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params = study.best_params\n",
    "print(\"Best hyperparameters: \", best_params)\n",
    "\n",
    "# Train the model with the best hyperparameters\n",
    "best_model = RandomForestRegressor(**best_params)\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the training, validation, and test sets with the best model\n",
    "y_train_pred_scaled = best_model.predict(X_train)\n",
    "y_valid_pred_scaled = best_model.predict(X_valid)\n",
    "y_test_pred_scaled = best_model.predict(X_test)\n",
    "\n",
    "# Inverse transform the scaled predictions and actual target values\n",
    "y_train_pred = scaler.inverse_transform(y_train_pred_scaled.reshape(-1, 1)).flatten()\n",
    "y_valid_pred = scaler.inverse_transform(y_valid_pred_scaled.reshape(-1, 1)).flatten()\n",
    "y_test_pred = scaler.inverse_transform(y_test_pred_scaled.reshape(-1, 1)).flatten()\n",
    "y_train_orig = scaler.inverse_transform(y_train.reshape(-1, 1)).flatten()\n",
    "y_valid_orig = scaler.inverse_transform(y_valid.reshape(-1, 1)).flatten()\n",
    "y_test_orig = scaler.inverse_transform(y_test.reshape(-1, 1)).flatten()\n",
    "\n",
    "# Calculate performance metrics on the original scale\n",
    "def print_metrics(y_true, y_pred, dataset_name):\n",
    "    print(f\"{dataset_name} Performance Metrics:\")\n",
    "    print(\"Mean Absolute Error (MAE): \", mean_absolute_error(y_true, y_pred))\n",
    "    print(\"Mean Squared Error (MSE): \", mean_squared_error(y_true, y_pred))\n",
    "    print(\"R-squared (R2): \", r2_score(y_true, y_pred))\n",
    "    print()\n",
    "\n",
    "# Print metrics for training, validation, and test data\n",
    "print(\"Performance with tuned hyperparameters:\")\n",
    "print_metrics(y_train_orig, y_train_pred, \"Training\")\n",
    "print_metrics(y_valid_orig, y_valid_pred, \"Validation\")\n",
    "print_metrics(y_test_orig, y_test_pred, \"Test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b68d28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the model\n",
    "joblib.dump(best_model, 'rf_model_without_lstm_london.joblib')\n",
    "\n",
    "# Load the model\n",
    "loaded_model = joblib.load('rf_model_without_lstm_london.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0cc35076",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance with loaded model:\n",
      "Training Performance Metrics:\n",
      "Mean Absolute Error (MAE):  38.8979661585169\n",
      "Mean Squared Error (MSE):  5717.891363256381\n",
      "R-squared (R2):  0.7201048500256542\n",
      "\n",
      "Validation Performance Metrics:\n",
      "Mean Absolute Error (MAE):  54.14299501633657\n",
      "Mean Squared Error (MSE):  10628.454063281602\n",
      "R-squared (R2):  0.5001656443033069\n",
      "\n",
      "Test Performance Metrics:\n",
      "Mean Absolute Error (MAE):  56.31900232784735\n",
      "Mean Squared Error (MSE):  13415.236518110458\n",
      "R-squared (R2):  0.48024313775087635\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Step 1: Load the scaled datasets\n",
    "scaled_train_df = pd.read_csv('scaled_train_data_without_LSTM.csv')\n",
    "scaled_valid_df = pd.read_csv('scaled_valid_data_without_LSTM.csv')\n",
    "scaled_test_df = pd.read_csv('scaled_test_data_without_LSTM.csv')\n",
    "\n",
    "# Separate features and target from the scaled datasets\n",
    "X_train = scaled_train_df.drop(columns=['price'])\n",
    "y_train = scaled_train_df['price']\n",
    "X_valid = scaled_valid_df.drop(columns=['price'])\n",
    "y_valid = scaled_valid_df['price']\n",
    "X_test = scaled_test_df.drop(columns=['price'])\n",
    "y_test = scaled_test_df['price']\n",
    "\n",
    "# Step 2: Load the scaler\n",
    "scaler = joblib.load('scaler_without_LSTM.pkl')\n",
    "\n",
    "# Step 3: Load the saved model\n",
    "loaded_model = joblib.load('rf_model_without_lstm_london.joblib')\n",
    "\n",
    "# Step 4: Make predictions using the loaded model\n",
    "y_train_pred_scaled = loaded_model.predict(X_train)\n",
    "y_valid_pred_scaled = loaded_model.predict(X_valid)\n",
    "y_test_pred_scaled = loaded_model.predict(X_test)\n",
    "\n",
    "# Step 5: Inverse transform the scaled predictions and actual target values\n",
    "y_train_pred = scaler.inverse_transform(y_train_pred_scaled.reshape(-1, 1)).flatten()\n",
    "y_valid_pred = scaler.inverse_transform(y_valid_pred_scaled.reshape(-1, 1)).flatten()\n",
    "y_test_pred = scaler.inverse_transform(y_test_pred_scaled.reshape(-1, 1)).flatten()\n",
    "y_train_orig = scaler.inverse_transform(y_train.values.reshape(-1, 1)).flatten()\n",
    "y_valid_orig = scaler.inverse_transform(y_valid.values.reshape(-1, 1)).flatten()\n",
    "y_test_orig = scaler.inverse_transform(y_test.values.reshape(-1, 1)).flatten()\n",
    "\n",
    "# Step 6: Calculate and print performance metrics on the original scale\n",
    "def print_metrics(y_true, y_pred, dataset_name):\n",
    "    print(f\"{dataset_name} Performance Metrics:\")\n",
    "    print(\"Mean Absolute Error (MAE): \", mean_absolute_error(y_true, y_pred))\n",
    "    print(\"Mean Squared Error (MSE): \", mean_squared_error(y_true, y_pred))\n",
    "    print(\"R-squared (R2): \", r2_score(y_true, y_pred))\n",
    "    print()\n",
    "\n",
    "# Print metrics for training, validation, and test data\n",
    "print(\"Performance with loaded model:\")\n",
    "print_metrics(y_train_orig, y_train_pred, \"Training\")\n",
    "print_metrics(y_valid_orig, y_valid_pred, \"Validation\")\n",
    "print_metrics(y_test_orig, y_test_pred, \"Test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f86e5681",
   "metadata": {},
   "source": [
    "## With LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43ebac99",
   "metadata": {},
   "source": [
    "#### Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "790941dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Excluded columns for scaling\n",
    "excluded_columns = ['id', 'host_id', 'longitude', 'latitude', 'date']\n",
    "\n",
    "# Prepare the data by dropping the unnecessary columns and separating features and target\n",
    "def prepare_data(data, target_column):\n",
    "    X = data.drop(columns=['id', 'host_id', 'date', target_column])\n",
    "    y = data[target_column]\n",
    "    return X, y\n",
    "\n",
    "# Scale the features and the target variable\n",
    "def scale_features_and_target(X, y, excluded_columns):\n",
    "    numerical_features = X.select_dtypes(include=['float64', 'int64']).columns.difference(excluded_columns)\n",
    "    scaler = RobustScaler()\n",
    "    X_scaled = X.copy()\n",
    "    X_scaled[numerical_features] = scaler.fit_transform(X[numerical_features])\n",
    "    y_scaled = scaler.fit_transform(y.values.reshape(-1, 1)).flatten()\n",
    "    return X_scaled, y_scaled, scaler\n",
    "\n",
    "# Prepare the training, validation, and test sets\n",
    "X_train_raw, y_train_raw = prepare_data(train_data_lstm_london, 'price')\n",
    "X_valid_raw, y_valid_raw = prepare_data(valid_data_lstm_london, 'price')\n",
    "X_test_raw, y_test_raw = prepare_data(test_data_lstm_london, 'price')\n",
    "\n",
    "# Apply scaling to both features and target\n",
    "X_train, y_train, scaler = scale_features_and_target(X_train_raw, y_train_raw, excluded_columns)\n",
    "X_valid, y_valid, _ = scale_features_and_target(X_valid_raw, y_valid_raw, excluded_columns)\n",
    "X_test, y_test, _ = scale_features_and_target(X_test_raw, y_test_raw, excluded_columns)\n",
    "\n",
    "# Function to optimize using Optuna\n",
    "def objective(trial):\n",
    "    param = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 500),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 15),\n",
    "        'min_samples_split': trial.suggest_int('min_samples_split', 5, 15),\n",
    "        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 5, 15),\n",
    "        'max_features': trial.suggest_categorical('max_features', [None, 'sqrt', 'log2'])\n",
    "    }\n",
    "\n",
    "    model = RandomForestRegressor(**param)\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_valid)\n",
    "    mse = mean_squared_error(y_valid, preds)\n",
    "    return mse\n",
    "\n",
    "# Create a study\n",
    "study = optuna.create_study(direction='minimize', sampler=TPESampler())\n",
    "study.optimize(objective, n_trials=50, show_progress_bar=True)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params = study.best_params\n",
    "print(\"Best hyperparameters: \", best_params)\n",
    "\n",
    "# Train the model with the best hyperparameters\n",
    "best_model = RandomForestRegressor(**best_params)\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the training, validation, and test sets with the best model\n",
    "y_train_pred_scaled = best_model.predict(X_train)\n",
    "y_valid_pred_scaled = best_model.predict(X_valid)\n",
    "y_test_pred_scaled = best_model.predict(X_test)\n",
    "\n",
    "# Inverse transform the scaled predictions and actual target values\n",
    "y_train_pred = scaler.inverse_transform(y_train_pred_scaled.reshape(-1, 1)).flatten()\n",
    "y_valid_pred = scaler.inverse_transform(y_valid_pred_scaled.reshape(-1, 1)).flatten()\n",
    "y_test_pred = scaler.inverse_transform(y_test_pred_scaled.reshape(-1, 1)).flatten()\n",
    "y_train_orig = scaler.inverse_transform(y_train.reshape(-1, 1)).flatten()\n",
    "y_valid_orig = scaler.inverse_transform(y_valid.reshape(-1, 1)).flatten()\n",
    "y_test_orig = scaler.inverse_transform(y_test.reshape(-1, 1)).flatten()\n",
    "\n",
    "# Calculate performance metrics on the original scale\n",
    "def print_metrics(y_true, y_pred, dataset_name):\n",
    "    print(f\"{dataset_name} Performance Metrics:\")\n",
    "    print(\"Mean Absolute Error (MAE): \", mean_absolute_error(y_true, y_pred))\n",
    "    print(\"Mean Squared Error (MSE): \", mean_squared_error(y_true, y_pred))\n",
    "    print(\"R-squared (R2): \", r2_score(y_true, y_pred))\n",
    "    print()\n",
    "\n",
    "# Print metrics for training, validation, and test data\n",
    "print(\"Performance with tuned hyperparameters:\")\n",
    "print_metrics(y_train_orig, y_train_pred, \"Training\")\n",
    "print_metrics(y_valid_orig, y_valid_pred, \"Validation\")\n",
    "print_metrics(y_test_orig, y_test_pred, \"Test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74376dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the model\n",
    "joblib.dump(best_model, 'rf_model_with_lstm_london.joblib')\n",
    "\n",
    "# Load the model\n",
    "loaded_model = joblib.load('rf_model_with_lstm_london.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2c41bf2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance with loaded model:\n",
      "Training Performance Metrics:\n",
      "Mean Absolute Error (MAE):  7.2113326379852065\n",
      "Mean Squared Error (MSE):  601.1875144688037\n",
      "R-squared (R2):  0.9700943662262261\n",
      "\n",
      "Validation Performance Metrics:\n",
      "Mean Absolute Error (MAE):  5.652138603023875\n",
      "Mean Squared Error (MSE):  257.67367129960985\n",
      "R-squared (R2):  0.9878293930658014\n",
      "\n",
      "Test Performance Metrics:\n",
      "Mean Absolute Error (MAE):  18.212488029430375\n",
      "Mean Squared Error (MSE):  1954.2410787740978\n",
      "R-squared (R2):  0.9239557775704101\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Step 1: Load the scaled datasets\n",
    "scaled_train_df = pd.read_csv('scaled_train_data_with_LSTM.csv')\n",
    "scaled_valid_df = pd.read_csv('scaled_valid_data_with_LSTM.csv')\n",
    "scaled_test_df = pd.read_csv('scaled_test_data_with_LSTM.csv')\n",
    "\n",
    "# Separate features and target from the scaled datasets\n",
    "X_train = scaled_train_df.drop(columns=['price'])\n",
    "y_train = scaled_train_df['price']\n",
    "X_valid = scaled_valid_df.drop(columns=['price'])\n",
    "y_valid = scaled_valid_df['price']\n",
    "X_test = scaled_test_df.drop(columns=['price'])\n",
    "y_test = scaled_test_df['price']\n",
    "\n",
    "# Step 2: Load the scaler\n",
    "scaler = joblib.load('scaler_with_LSTM.pkl')\n",
    "\n",
    "# Step 3: Load the saved model\n",
    "loaded_model = joblib.load('rf_model_with_lstm_london.joblib')\n",
    "\n",
    "# Step 4: Make predictions using the loaded model\n",
    "y_train_pred_scaled = loaded_model.predict(X_train)\n",
    "y_valid_pred_scaled = loaded_model.predict(X_valid)\n",
    "y_test_pred_scaled = loaded_model.predict(X_test)\n",
    "\n",
    "# Step 5: Inverse transform the scaled predictions and actual target values\n",
    "y_train_pred = scaler.inverse_transform(y_train_pred_scaled.reshape(-1, 1)).flatten()\n",
    "y_valid_pred = scaler.inverse_transform(y_valid_pred_scaled.reshape(-1, 1)).flatten()\n",
    "y_test_pred = scaler.inverse_transform(y_test_pred_scaled.reshape(-1, 1)).flatten()\n",
    "y_train_orig = scaler.inverse_transform(y_train.values.reshape(-1, 1)).flatten()\n",
    "y_valid_orig = scaler.inverse_transform(y_valid.values.reshape(-1, 1)).flatten()\n",
    "y_test_orig = scaler.inverse_transform(y_test.values.reshape(-1, 1)).flatten()\n",
    "\n",
    "# Step 6: Calculate and print performance metrics on the original scale\n",
    "def print_metrics(y_true, y_pred, dataset_name):\n",
    "    print(f\"{dataset_name} Performance Metrics:\")\n",
    "    print(\"Mean Absolute Error (MAE): \", mean_absolute_error(y_true, y_pred))\n",
    "    print(\"Mean Squared Error (MSE): \", mean_squared_error(y_true, y_pred))\n",
    "    print(\"R-squared (R2): \", r2_score(y_true, y_pred))\n",
    "    print()\n",
    "\n",
    "# Print metrics for training, validation, and test data\n",
    "print(\"Performance with loaded model:\")\n",
    "print_metrics(y_train_orig, y_train_pred, \"Training\")\n",
    "print_metrics(y_valid_orig, y_valid_pred, \"Validation\")\n",
    "print_metrics(y_test_orig, y_test_pred, \"Test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b66a802",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f66bd8b",
   "metadata": {},
   "source": [
    "## Without LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecde530f",
   "metadata": {},
   "source": [
    "#### Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a581262e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Excluded columns for scaling\n",
    "excluded_columns = ['id', 'host_id', 'longitude', 'latitude', 'date']\n",
    "\n",
    "# Prepare the data by dropping the unnecessary columns and separating features and target\n",
    "def prepare_data(data, target_column):\n",
    "    X = data.drop(columns=['id', 'host_id', 'date', target_column])\n",
    "    y = data[target_column]\n",
    "    return X, y\n",
    "\n",
    "# Scale the features and the target variable\n",
    "def scale_features_and_target(X, y, excluded_columns):\n",
    "    numerical_features = X.select_dtypes(include=['float64', 'int64']).columns.difference(excluded_columns)\n",
    "    scaler = RobustScaler()\n",
    "    X_scaled = X.copy()\n",
    "    X_scaled[numerical_features] = scaler.fit_transform(X[numerical_features])\n",
    "    y_scaled = scaler.fit_transform(y.values.reshape(-1, 1)).flatten()\n",
    "    return X_scaled, y_scaled, scaler\n",
    "\n",
    "# Prepare the training, validation, and test sets\n",
    "X_train_raw, y_train_raw = prepare_data(train_data_london, 'price')\n",
    "X_valid_raw, y_valid_raw = prepare_data(valid_data_london, 'price')\n",
    "X_test_raw, y_test_raw = prepare_data(test_data_london, 'price')\n",
    "\n",
    "# Apply scaling to both features and target\n",
    "X_train_scaled, y_train_scaled, scaler = scale_features_and_target(X_train_raw, y_train_raw, excluded_columns)\n",
    "X_valid_scaled, y_valid_scaled, _ = scale_features_and_target(X_valid_raw, y_valid_raw, excluded_columns)\n",
    "X_test_scaled, y_test_scaled, _ = scale_features_and_target(X_test_raw, y_test_raw, excluded_columns)\n",
    "\n",
    "# Function to optimize using Optuna\n",
    "def objective(trial):\n",
    "    fit_intercept = trial.suggest_categorical('fit_intercept', [True, False])\n",
    "\n",
    "    model = LinearRegression(fit_intercept=fit_intercept)\n",
    "    model.fit(X_train_scaled, y_train_scaled)\n",
    "    preds = model.predict(X_valid_scaled)\n",
    "    mse = mean_squared_error(y_valid_scaled, preds)\n",
    "    return mse\n",
    "\n",
    "# Create a study\n",
    "study = optuna.create_study(direction='minimize', sampler=TPESampler())\n",
    "study.optimize(objective, n_trials=50, show_progress_bar=True)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params = study.best_params\n",
    "print(\"Best hyperparameters: \", best_params)\n",
    "\n",
    "# Train the model with the best hyperparameters\n",
    "best_model = LinearRegression(**best_params)\n",
    "best_model.fit(X_train_scaled, y_train_scaled)\n",
    "\n",
    "# Predict on the training, validation, and test sets with the best model\n",
    "y_train_pred_scaled = best_model.predict(X_train_scaled)\n",
    "y_valid_pred_scaled = best_model.predict(X_valid_scaled)\n",
    "y_test_pred_scaled = best_model.predict(X_test_scaled)\n",
    "\n",
    "# Inverse transform the scaled predictions and actual target values\n",
    "y_train_pred = scaler.inverse_transform(y_train_pred_scaled.reshape(-1, 1)).flatten()\n",
    "y_valid_pred = scaler.inverse_transform(y_valid_pred_scaled.reshape(-1, 1)).flatten()\n",
    "y_test_pred = scaler.inverse_transform(y_test_pred_scaled.reshape(-1, 1)).flatten()\n",
    "y_train_orig = scaler.inverse_transform(y_train_scaled.reshape(-1, 1)).flatten()\n",
    "y_valid_orig = scaler.inverse_transform(y_valid_scaled.reshape(-1, 1)).flatten()\n",
    "y_test_orig = scaler.inverse_transform(y_test_scaled.reshape(-1, 1)).flatten()\n",
    "\n",
    "# Calculate performance metrics on the original scale\n",
    "def print_metrics(y_true, y_pred, dataset_name):\n",
    "    print(f\"{dataset_name} Performance Metrics:\")\n",
    "    print(\"Mean Absolute Error (MAE): \", mean_absolute_error(y_true, y_pred))\n",
    "    print(\"Mean Squared Error (MSE): \", mean_squared_error(y_true, y_pred))\n",
    "    print(\"R-squared (R2): \", r2_score(y_true, y_pred))\n",
    "    print()\n",
    "\n",
    "# Print metrics for training, validation, and test data\n",
    "print(\"Performance with tuned hyperparameters:\")\n",
    "print_metrics(y_train_orig, y_train_pred, \"Training\")\n",
    "print_metrics(y_valid_orig, y_valid_pred, \"Validation\")\n",
    "print_metrics(y_test_orig, y_test_pred, \"Test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dfcdc0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the model\n",
    "joblib.dump(best_model, 'linear_model_without_lstm_london.joblib')\n",
    "\n",
    "# Load the model\n",
    "loaded_model = joblib.load('linear_model_without_lstm_london.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0487645a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance with loaded model:\n",
      "Training Performance Metrics:\n",
      "Mean Absolute Error (MAE):  56.3513335537666\n",
      "Mean Squared Error (MSE):  10051.333503050357\n",
      "R-squared (R2):  0.5079795470832029\n",
      "\n",
      "Validation Performance Metrics:\n",
      "Mean Absolute Error (MAE):  60.665459604276826\n",
      "Mean Squared Error (MSE):  11871.247784605584\n",
      "R-squared (R2):  0.4417196092295972\n",
      "\n",
      "Test Performance Metrics:\n",
      "Mean Absolute Error (MAE):  61.17094442216732\n",
      "Mean Squared Error (MSE):  13869.489158198909\n",
      "R-squared (R2):  0.46264367712548826\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Step 1: Load the scaled datasets\n",
    "scaled_train_df = pd.read_csv('scaled_train_data_without_LSTM.csv')\n",
    "scaled_valid_df = pd.read_csv('scaled_valid_data_without_LSTM.csv')\n",
    "scaled_test_df = pd.read_csv('scaled_test_data_without_LSTM.csv')\n",
    "\n",
    "# Separate features and target from the scaled datasets\n",
    "X_train = scaled_train_df.drop(columns=['price'])\n",
    "y_train = scaled_train_df['price']\n",
    "X_valid = scaled_valid_df.drop(columns=['price'])\n",
    "y_valid = scaled_valid_df['price']\n",
    "X_test = scaled_test_df.drop(columns=['price'])\n",
    "y_test = scaled_test_df['price']\n",
    "\n",
    "# Step 2: Load the scaler\n",
    "scaler = joblib.load('scaler_without_LSTM.pkl')\n",
    "\n",
    "# Step 3: Load the saved model\n",
    "loaded_model = joblib.load('linear_model_without_lstm_london.joblib')\n",
    "\n",
    "# Step 4: Make predictions using the loaded model\n",
    "y_train_pred_scaled = loaded_model.predict(X_train)\n",
    "y_valid_pred_scaled = loaded_model.predict(X_valid)\n",
    "y_test_pred_scaled = loaded_model.predict(X_test)\n",
    "\n",
    "# Step 5: Inverse transform the scaled predictions and actual target values\n",
    "y_train_pred = scaler.inverse_transform(y_train_pred_scaled.reshape(-1, 1)).flatten()\n",
    "y_valid_pred = scaler.inverse_transform(y_valid_pred_scaled.reshape(-1, 1)).flatten()\n",
    "y_test_pred = scaler.inverse_transform(y_test_pred_scaled.reshape(-1, 1)).flatten()\n",
    "y_train_orig = scaler.inverse_transform(y_train.values.reshape(-1, 1)).flatten()\n",
    "y_valid_orig = scaler.inverse_transform(y_valid.values.reshape(-1, 1)).flatten()\n",
    "y_test_orig = scaler.inverse_transform(y_test.values.reshape(-1, 1)).flatten()\n",
    "\n",
    "# Step 6: Calculate and print performance metrics on the original scale\n",
    "def print_metrics(y_true, y_pred, dataset_name):\n",
    "    print(f\"{dataset_name} Performance Metrics:\")\n",
    "    print(\"Mean Absolute Error (MAE): \", mean_absolute_error(y_true, y_pred))\n",
    "    print(\"Mean Squared Error (MSE): \", mean_squared_error(y_true, y_pred))\n",
    "    print(\"R-squared (R2): \", r2_score(y_true, y_pred))\n",
    "    print()\n",
    "\n",
    "# Print metrics for training, validation, and test data\n",
    "print(\"Performance with loaded model:\")\n",
    "print_metrics(y_train_orig, y_train_pred, \"Training\")\n",
    "print_metrics(y_valid_orig, y_valid_pred, \"Validation\")\n",
    "print_metrics(y_test_orig, y_test_pred, \"Test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "947128e9",
   "metadata": {},
   "source": [
    "## With LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84939f87",
   "metadata": {},
   "source": [
    "#### hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9690fe5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Excluded columns for scaling\n",
    "excluded_columns = ['id', 'host_id', 'longitude', 'latitude', 'date']\n",
    "\n",
    "# Prepare the data by dropping unnecessary columns and separating features and target\n",
    "def prepare_data(data, target_column):\n",
    "    X = data.drop(columns=['id', 'host_id', 'date', target_column])\n",
    "    y = data[target_column]\n",
    "    return X, y\n",
    "\n",
    "# Scale the features and the target variable\n",
    "def scale_features_and_target(X, y, excluded_columns):\n",
    "    numerical_features = X.select_dtypes(include=['float64', 'int64']).columns.difference(excluded_columns)\n",
    "    scaler = RobustScaler()\n",
    "    X_scaled = X.copy()\n",
    "    X_scaled[numerical_features] = scaler.fit_transform(X[numerical_features])\n",
    "    y_scaled = scaler.fit_transform(y.values.reshape(-1, 1)).flatten()\n",
    "    return X_scaled, y_scaled, scaler\n",
    "\n",
    "# Prepare the training, validation, and test sets for LSTM data\n",
    "X_train_raw, y_train_raw = prepare_data(train_data_lstm_london, 'price')\n",
    "X_valid_raw, y_valid_raw = prepare_data(valid_data_lstm_london, 'price')\n",
    "X_test_raw, y_test_raw = prepare_data(test_data_lstm_london, 'price')\n",
    "\n",
    "# Apply scaling to both features and target\n",
    "X_train_scaled, y_train_scaled, scaler = scale_features_and_target(X_train_raw, y_train_raw, excluded_columns)\n",
    "X_valid_scaled, y_valid_scaled, _ = scale_features_and_target(X_valid_raw, y_valid_raw, excluded_columns)\n",
    "X_test_scaled, y_test_scaled, _ = scale_features_and_target(X_test_raw, y_test_raw, excluded_columns)\n",
    "\n",
    "# Function to optimize using Optuna\n",
    "def objective(trial):    \n",
    "    fit_intercept = trial.suggest_categorical('fit_intercept', [True, False])\n",
    "\n",
    "    model = LinearRegression(fit_intercept=fit_intercept)\n",
    "    model.fit(X_train_scaled, y_train_scaled)\n",
    "    preds = model.predict(X_valid_scaled)\n",
    "    mse = mean_squared_error(y_valid_scaled, preds)\n",
    "    return mse\n",
    "\n",
    "# Create a study\n",
    "study = optuna.create_study(direction='minimize', sampler=TPESampler())\n",
    "study.optimize(objective, n_trials=50, show_progress_bar=True)\n",
    "\n",
    "# Since there are no hyperparameters to tune, we use a default Linear Regression model\n",
    "best_model = LinearRegression()\n",
    "best_model.fit(X_train_scaled, y_train_scaled)\n",
    "\n",
    "# Predict on the training, validation, and test sets with the best model\n",
    "y_train_pred_scaled = best_model.predict(X_train_scaled)\n",
    "y_valid_pred_scaled = best_model.predict(X_valid_scaled)\n",
    "y_test_pred_scaled = best_model.predict(X_test_scaled)\n",
    "\n",
    "# Inverse transform the scaled predictions and actual target values\n",
    "y_train_pred = scaler.inverse_transform(y_train_pred_scaled.reshape(-1, 1)).flatten()\n",
    "y_valid_pred = scaler.inverse_transform(y_valid_pred_scaled.reshape(-1, 1)).flatten()\n",
    "y_test_pred = scaler.inverse_transform(y_test_pred_scaled.reshape(-1, 1)).flatten()\n",
    "y_train_orig = scaler.inverse_transform(y_train_scaled.reshape(-1, 1)).flatten()\n",
    "y_valid_orig = scaler.inverse_transform(y_valid_scaled.reshape(-1, 1)).flatten()\n",
    "y_test_orig = scaler.inverse_transform(y_test_scaled.reshape(-1, 1)).flatten()\n",
    "\n",
    "# Calculate performance metrics on the original scale\n",
    "def print_metrics(y_true, y_pred, dataset_name):\n",
    "    print(f\"{dataset_name} Performance Metrics:\")\n",
    "    print(\"Mean Absolute Error (MAE): \", mean_absolute_error(y_true, y_pred))\n",
    "    print(\"Mean Squared Error (MSE): \", mean_squared_error(y_true, y_pred))\n",
    "    print(\"R-squared (R2): \", r2_score(y_true, y_pred))\n",
    "    print()\n",
    "\n",
    "# Print metrics for training, validation, and test data\n",
    "print_metrics(y_train_orig, y_train_pred, \"Training\")\n",
    "print_metrics(y_valid_orig, y_valid_pred, \"Validation\")\n",
    "print_metrics(y_test_orig, y_test_pred, \"Test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e4bde9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the model\n",
    "joblib.dump(best_model, 'linear_model_with_lstm_london.joblib')\n",
    "\n",
    "# Load the model\n",
    "loaded_model = joblib.load('linear_model_with_lstm_london.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ee681bc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance with loaded model:\n",
      "Training Performance Metrics:\n",
      "Mean Absolute Error (MAE):  14.365095058109864\n",
      "Mean Squared Error (MSE):  939.4170904260836\n",
      "R-squared (R2):  0.9532693830278065\n",
      "\n",
      "Validation Performance Metrics:\n",
      "Mean Absolute Error (MAE):  23.231317315340043\n",
      "Mean Squared Error (MSE):  1769.186753270641\n",
      "R-squared (R2):  0.9164366446185668\n",
      "\n",
      "Test Performance Metrics:\n",
      "Mean Absolute Error (MAE):  557.8254491564902\n",
      "Mean Squared Error (MSE):  1493667.5606022098\n",
      "R-squared (R2):  -57.12219866217805\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Step 1: Load the scaled datasets\n",
    "scaled_train_df = pd.read_csv('scaled_train_data_with_LSTM.csv')\n",
    "scaled_valid_df = pd.read_csv('scaled_valid_data_with_LSTM.csv')\n",
    "scaled_test_df = pd.read_csv('scaled_test_data_with_LSTM.csv')\n",
    "\n",
    "# Separate features and target from the scaled datasets\n",
    "X_train = scaled_train_df.drop(columns=['price'])\n",
    "y_train = scaled_train_df['price']\n",
    "X_valid = scaled_valid_df.drop(columns=['price'])\n",
    "y_valid = scaled_valid_df['price']\n",
    "X_test = scaled_test_df.drop(columns=['price'])\n",
    "y_test = scaled_test_df['price']\n",
    "\n",
    "# Step 2: Load the scaler\n",
    "scaler = joblib.load('scaler_with_LSTM.pkl')\n",
    "\n",
    "# Step 3: Load the saved model\n",
    "loaded_model = joblib.load('linear_model_with_lstm_london.joblib')\n",
    "\n",
    "# Step 4: Make predictions using the loaded model\n",
    "y_train_pred_scaled = loaded_model.predict(X_train)\n",
    "y_valid_pred_scaled = loaded_model.predict(X_valid)\n",
    "y_test_pred_scaled = loaded_model.predict(X_test)\n",
    "\n",
    "# Step 5: Inverse transform the scaled predictions and actual target values\n",
    "y_train_pred = scaler.inverse_transform(y_train_pred_scaled.reshape(-1, 1)).flatten()\n",
    "y_valid_pred = scaler.inverse_transform(y_valid_pred_scaled.reshape(-1, 1)).flatten()\n",
    "y_test_pred = scaler.inverse_transform(y_test_pred_scaled.reshape(-1, 1)).flatten()\n",
    "y_train_orig = scaler.inverse_transform(y_train.values.reshape(-1, 1)).flatten()\n",
    "y_valid_orig = scaler.inverse_transform(y_valid.values.reshape(-1, 1)).flatten()\n",
    "y_test_orig = scaler.inverse_transform(y_test.values.reshape(-1, 1)).flatten()\n",
    "\n",
    "# Step 6: Calculate and print performance metrics on the original scale\n",
    "def print_metrics(y_true, y_pred, dataset_name):\n",
    "    print(f\"{dataset_name} Performance Metrics:\")\n",
    "    print(\"Mean Absolute Error (MAE): \", mean_absolute_error(y_true, y_pred))\n",
    "    print(\"Mean Squared Error (MSE): \", mean_squared_error(y_true, y_pred))\n",
    "    print(\"R-squared (R2): \", r2_score(y_true, y_pred))\n",
    "    print()\n",
    "\n",
    "# Print metrics for training, validation, and test data\n",
    "print(\"Performance with loaded model:\")\n",
    "print_metrics(y_train_orig, y_train_pred, \"Training\")\n",
    "print_metrics(y_valid_orig, y_valid_pred, \"Validation\")\n",
    "print_metrics(y_test_orig, y_test_pred, \"Test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "034e777f",
   "metadata": {},
   "source": [
    "## Ridge Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a548a18",
   "metadata": {},
   "source": [
    "## Without LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "377df321",
   "metadata": {},
   "source": [
    "#### Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732031c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Excluded columns for scaling\n",
    "excluded_columns = ['id', 'host_id', 'longitude', 'latitude', 'date']\n",
    "\n",
    "# Prepare the data by dropping unnecessary columns and separating features and target\n",
    "def prepare_data(data, target_column):\n",
    "    X = data.drop(columns=['id', 'host_id', 'date', target_column])\n",
    "    y = data[target_column]\n",
    "    return X, y\n",
    "\n",
    "# Scale the features and the target variable\n",
    "def scale_features_and_target(X, y, excluded_columns):\n",
    "    numerical_features = X.select_dtypes(include=['float64', 'int64']).columns.difference(excluded_columns)\n",
    "    scaler = RobustScaler()\n",
    "    X_scaled = X.copy()\n",
    "    X_scaled[numerical_features] = scaler.fit_transform(X[numerical_features])\n",
    "    y_scaled = scaler.fit_transform(y.values.reshape(-1, 1)).flatten()\n",
    "    return X_scaled, y_scaled, scaler\n",
    "\n",
    "# Prepare the training, validation, and test sets\n",
    "X_train_raw, y_train_raw = prepare_data(train_data_london, 'price')\n",
    "X_valid_raw, y_valid_raw = prepare_data(valid_data_london, 'price')\n",
    "X_test_raw, y_test_raw = prepare_data(test_data_london, 'price')\n",
    "\n",
    "# Apply scaling to both features and target\n",
    "X_train_scaled, y_train_scaled, scaler = scale_features_and_target(X_train_raw, y_train_raw, excluded_columns)\n",
    "X_valid_scaled, y_valid_scaled, _ = scale_features_and_target(X_valid_raw, y_valid_raw, excluded_columns)\n",
    "X_test_scaled, y_test_scaled, _ = scale_features_and_target(X_test_raw, y_test_raw, excluded_columns)\n",
    "\n",
    "# Function to optimize using Optuna\n",
    "def objective(trial):\n",
    "    alpha = trial.suggest_float('alpha', 0.1, 10.0, log=True)\n",
    "    fit_intercept = trial.suggest_categorical('fit_intercept', [True, False])\n",
    "\n",
    "    model = Ridge(alpha=alpha, fit_intercept=fit_intercept)\n",
    "    model.fit(X_train_scaled, y_train_scaled)\n",
    "    preds = model.predict(X_valid_scaled)\n",
    "    mse = mean_squared_error(y_valid_scaled, preds)\n",
    "    return mse\n",
    "\n",
    "# Create a study\n",
    "study = optuna.create_study(direction='minimize', sampler=TPESampler())\n",
    "study.optimize(objective, n_trials=50, show_progress_bar=True)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params = study.best_params\n",
    "print(\"Best hyperparameters: \", best_params)\n",
    "\n",
    "# Train the model with the best hyperparameters\n",
    "best_model = Ridge(**best_params)\n",
    "best_model.fit(X_train_scaled, y_train_scaled)\n",
    "\n",
    "# Predict on the training, validation, and test sets with the best model\n",
    "y_train_pred_scaled = best_model.predict(X_train_scaled)\n",
    "y_valid_pred_scaled = best_model.predict(X_valid_scaled)\n",
    "y_test_pred_scaled = best_model.predict(X_test_scaled)\n",
    "\n",
    "# Inverse transform the scaled predictions and actual target values\n",
    "y_train_pred = scaler.inverse_transform(y_train_pred_scaled.reshape(-1, 1)).flatten()\n",
    "y_valid_pred = scaler.inverse_transform(y_valid_pred_scaled.reshape(-1, 1)).flatten()\n",
    "y_test_pred = scaler.inverse_transform(y_test_pred_scaled.reshape(-1, 1)).flatten()\n",
    "y_train_orig = scaler.inverse_transform(y_train_scaled.reshape(-1, 1)).flatten()\n",
    "y_valid_orig = scaler.inverse_transform(y_valid_scaled.reshape(-1, 1)).flatten()\n",
    "y_test_orig = scaler.inverse_transform(y_test_scaled.reshape(-1, 1)).flatten()\n",
    "\n",
    "# Calculate performance metrics on the original scale\n",
    "def print_metrics(y_true, y_pred, dataset_name):\n",
    "    print(f\"{dataset_name} Performance Metrics:\")\n",
    "    print(\"Mean Absolute Error (MAE): \", mean_absolute_error(y_true, y_pred))\n",
    "    print(\"Mean Squared Error (MSE): \", mean_squared_error(y_true, y_pred))\n",
    "    print(\"R-squared (R2): \", r2_score(y_true, y_pred))\n",
    "    print()\n",
    "\n",
    "# Print metrics for training, validation, and test data\n",
    "print(\"Performance with tuned hyperparameters:\")\n",
    "print_metrics(y_train_orig, y_train_pred, \"Training\")\n",
    "print_metrics(y_valid_orig, y_valid_pred, \"Validation\")\n",
    "print_metrics(y_test_orig, y_test_pred, \"Test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45b6153",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the model\n",
    "joblib.dump(best_model, 'ridge_model_without_lstm_london.joblib')\n",
    "\n",
    "# Load the model\n",
    "loaded_model = joblib.load('ridge_model_without_lstm_london.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9a24ba91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance with loaded model:\n",
      "Training Performance Metrics:\n",
      "Mean Absolute Error (MAE):  56.162600070060115\n",
      "Mean Squared Error (MSE):  10061.77788504465\n",
      "R-squared (R2):  0.5074682866064006\n",
      "\n",
      "Validation Performance Metrics:\n",
      "Mean Absolute Error (MAE):  60.442177855699065\n",
      "Mean Squared Error (MSE):  11858.363143747254\n",
      "R-squared (R2):  0.4423255474143476\n",
      "\n",
      "Test Performance Metrics:\n",
      "Mean Absolute Error (MAE):  60.95167178730608\n",
      "Mean Squared Error (MSE):  13862.87250961498\n",
      "R-squared (R2):  0.46290003104827926\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Step 1: Load the scaled datasets\n",
    "scaled_train_df = pd.read_csv('scaled_train_data_without_LSTM.csv')\n",
    "scaled_valid_df = pd.read_csv('scaled_valid_data_without_LSTM.csv')\n",
    "scaled_test_df = pd.read_csv('scaled_test_data_without_LSTM.csv')\n",
    "\n",
    "# Separate features and target from the scaled datasets\n",
    "X_train = scaled_train_df.drop(columns=['price'])\n",
    "y_train = scaled_train_df['price']\n",
    "X_valid = scaled_valid_df.drop(columns=['price'])\n",
    "y_valid = scaled_valid_df['price']\n",
    "X_test = scaled_test_df.drop(columns=['price'])\n",
    "y_test = scaled_test_df['price']\n",
    "\n",
    "# Step 2: Load the scaler\n",
    "scaler = joblib.load('scaler_without_LSTM.pkl')\n",
    "\n",
    "# Step 3: Load the saved model\n",
    "loaded_model = joblib.load('ridge_model_without_lstm_london.joblib')\n",
    "\n",
    "# Step 4: Make predictions using the loaded model\n",
    "y_train_pred_scaled = loaded_model.predict(X_train)\n",
    "y_valid_pred_scaled = loaded_model.predict(X_valid)\n",
    "y_test_pred_scaled = loaded_model.predict(X_test)\n",
    "\n",
    "# Step 5: Inverse transform the scaled predictions and actual target values\n",
    "y_train_pred = scaler.inverse_transform(y_train_pred_scaled.reshape(-1, 1)).flatten()\n",
    "y_valid_pred = scaler.inverse_transform(y_valid_pred_scaled.reshape(-1, 1)).flatten()\n",
    "y_test_pred = scaler.inverse_transform(y_test_pred_scaled.reshape(-1, 1)).flatten()\n",
    "y_train_orig = scaler.inverse_transform(y_train.values.reshape(-1, 1)).flatten()\n",
    "y_valid_orig = scaler.inverse_transform(y_valid.values.reshape(-1, 1)).flatten()\n",
    "y_test_orig = scaler.inverse_transform(y_test.values.reshape(-1, 1)).flatten()\n",
    "\n",
    "# Step 6: Calculate and print performance metrics on the original scale\n",
    "def print_metrics(y_true, y_pred, dataset_name):\n",
    "    print(f\"{dataset_name} Performance Metrics:\")\n",
    "    print(\"Mean Absolute Error (MAE): \", mean_absolute_error(y_true, y_pred))\n",
    "    print(\"Mean Squared Error (MSE): \", mean_squared_error(y_true, y_pred))\n",
    "    print(\"R-squared (R2): \", r2_score(y_true, y_pred))\n",
    "    print()\n",
    "\n",
    "# Print metrics for training, validation, and test data\n",
    "print(\"Performance with loaded model:\")\n",
    "print_metrics(y_train_orig, y_train_pred, \"Training\")\n",
    "print_metrics(y_valid_orig, y_valid_pred, \"Validation\")\n",
    "print_metrics(y_test_orig, y_test_pred, \"Test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2419306",
   "metadata": {},
   "source": [
    "## With LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b9a21c7",
   "metadata": {},
   "source": [
    "#### hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe538d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Excluded columns for scaling\n",
    "excluded_columns = ['id', 'host_id', 'longitude', 'latitude', 'date']\n",
    "\n",
    "# Prepare the data by dropping unnecessary columns and separating features and target\n",
    "def prepare_data(data, target_column):\n",
    "    X = data.drop(columns=['id', 'host_id', 'date', target_column])\n",
    "    y = data[target_column]\n",
    "    return X, y\n",
    "\n",
    "# Scale the features and the target variable\n",
    "def scale_features_and_target(X, y, excluded_columns):\n",
    "    numerical_features = X.select_dtypes(include=['float64', 'int64']).columns.difference(excluded_columns)\n",
    "    scaler = RobustScaler()\n",
    "    X_scaled = X.copy()\n",
    "    X_scaled[numerical_features] = scaler.fit_transform(X[numerical_features])\n",
    "    y_scaled = scaler.fit_transform(y.values.reshape(-1, 1)).flatten()\n",
    "    return X_scaled, y_scaled, scaler\n",
    "\n",
    "# Prepare the training, validation, and test sets\n",
    "X_train_raw, y_train_raw = prepare_data(train_data_lstm_london, 'price')\n",
    "X_valid_raw, y_valid_raw = prepare_data(valid_data_lstm_london, 'price')\n",
    "X_test_raw, y_test_raw = prepare_data(test_data_lstm_london, 'price')\n",
    "\n",
    "# Apply scaling to both features and target\n",
    "X_train_scaled, y_train_scaled, scaler = scale_features_and_target(X_train_raw, y_train_raw, excluded_columns)\n",
    "X_valid_scaled, y_valid_scaled, _ = scale_features_and_target(X_valid_raw, y_valid_raw, excluded_columns)\n",
    "X_test_scaled, y_test_scaled, _ = scale_features_and_target(X_test_raw, y_test_raw, excluded_columns)\n",
    "\n",
    "# Function to optimize using Optuna\n",
    "def objective(trial):\n",
    "    param = {\n",
    "        'alpha': trial.suggest_float('alpha', 0.1, 10.0, log=True)\n",
    "    }\n",
    "\n",
    "    model = Ridge(**param)\n",
    "    model.fit(X_train_scaled, y_train_scaled)\n",
    "    preds = model.predict(X_valid_scaled)\n",
    "    mse = mean_squared_error(y_valid_scaled, preds)\n",
    "    return mse\n",
    "\n",
    "# Create a study\n",
    "study = optuna.create_study(direction='minimize', sampler=TPESampler())\n",
    "study.optimize(objective, n_trials=50, show_progress_bar=True)\n",
    "\n",
    "# Get the best hyperparameters and train the final model\n",
    "best_params = study.best_params\n",
    "best_model = Ridge(**best_params)\n",
    "best_model.fit(X_train_scaled, y_train_scaled)\n",
    "\n",
    "# Predict on the training, validation, and test sets with the best model\n",
    "y_train_pred_scaled = best_model.predict(X_train_scaled)\n",
    "y_valid_pred_scaled = best_model.predict(X_valid_scaled)\n",
    "y_test_pred_scaled = best_model.predict(X_test_scaled)\n",
    "\n",
    "# Inverse transform the scaled predictions and actual target values\n",
    "y_train_pred = scaler.inverse_transform(y_train_pred_scaled.reshape(-1, 1)).flatten()\n",
    "y_valid_pred = scaler.inverse_transform(y_valid_pred_scaled.reshape(-1, 1)).flatten()\n",
    "y_test_pred = scaler.inverse_transform(y_test_pred_scaled.reshape(-1, 1)).flatten()\n",
    "y_train_orig = scaler.inverse_transform(y_train_scaled.reshape(-1, 1)).flatten()\n",
    "y_valid_orig = scaler.inverse_transform(y_valid_scaled.reshape(-1, 1)).flatten()\n",
    "y_test_orig = scaler.inverse_transform(y_test_scaled.reshape(-1, 1)).flatten()\n",
    "\n",
    "# Calculate performance metrics on the original scale\n",
    "def print_metrics(y_true, y_pred, dataset_name):\n",
    "    print(f\"{dataset_name} Performance Metrics:\")\n",
    "    print(\"Mean Absolute Error (MAE): \", mean_absolute_error(y_true, y_pred))\n",
    "    print(\"Mean Squared Error (MSE): \", mean_squared_error(y_true, y_pred))\n",
    "    print(\"R-squared (R2): \", r2_score(y_true, y_pred))\n",
    "    print()\n",
    "\n",
    "# Print metrics for training, validation, and test data\n",
    "print_metrics(y_train_orig, y_train_pred, \"Training\")\n",
    "print_metrics(y_valid_orig, y_valid_pred, \"Validation\")\n",
    "print_metrics(y_test_orig, y_test_pred, \"Test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d562a61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the model\n",
    "joblib.dump(best_model, 'ridge_model_with_lstm_london.joblib')\n",
    "\n",
    "# Load the model\n",
    "loaded_model = joblib.load('ridge_model_with_lstm_london.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "72d9f17b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance with loaded model:\n",
      "Training Performance Metrics:\n",
      "Mean Absolute Error (MAE):  13.573215567168551\n",
      "Mean Squared Error (MSE):  994.7896239927906\n",
      "R-squared (R2):  0.9505149167920346\n",
      "\n",
      "Validation Performance Metrics:\n",
      "Mean Absolute Error (MAE):  11.98949531699229\n",
      "Mean Squared Error (MSE):  364.7579308892704\n",
      "R-squared (R2):  0.982771521123619\n",
      "\n",
      "Test Performance Metrics:\n",
      "Mean Absolute Error (MAE):  37.20260066892077\n",
      "Mean Squared Error (MSE):  2865.5959193536464\n",
      "R-squared (R2):  0.8884927679335497\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Step 1: Load the scaled datasets\n",
    "scaled_train_df = pd.read_csv('scaled_train_data_with_LSTM.csv')\n",
    "scaled_valid_df = pd.read_csv('scaled_valid_data_with_LSTM.csv')\n",
    "scaled_test_df = pd.read_csv('scaled_test_data_with_LSTM.csv')\n",
    "\n",
    "# Separate features and target from the scaled datasets\n",
    "X_train = scaled_train_df.drop(columns=['price'])\n",
    "y_train = scaled_train_df['price']\n",
    "X_valid = scaled_valid_df.drop(columns=['price'])\n",
    "y_valid = scaled_valid_df['price']\n",
    "X_test = scaled_test_df.drop(columns=['price'])\n",
    "y_test = scaled_test_df['price']\n",
    "\n",
    "# Step 2: Load the scaler\n",
    "scaler = joblib.load('scaler_with_LSTM.pkl')\n",
    "\n",
    "# Step 3: Load the saved model\n",
    "loaded_model = joblib.load('ridge_model_with_lstm_london.joblib')\n",
    "\n",
    "# Step 4: Make predictions using the loaded model\n",
    "y_train_pred_scaled = loaded_model.predict(X_train)\n",
    "y_valid_pred_scaled = loaded_model.predict(X_valid)\n",
    "y_test_pred_scaled = loaded_model.predict(X_test)\n",
    "\n",
    "# Step 5: Inverse transform the scaled predictions and actual target values\n",
    "y_train_pred = scaler.inverse_transform(y_train_pred_scaled.reshape(-1, 1)).flatten()\n",
    "y_valid_pred = scaler.inverse_transform(y_valid_pred_scaled.reshape(-1, 1)).flatten()\n",
    "y_test_pred = scaler.inverse_transform(y_test_pred_scaled.reshape(-1, 1)).flatten()\n",
    "y_train_orig = scaler.inverse_transform(y_train.values.reshape(-1, 1)).flatten()\n",
    "y_valid_orig = scaler.inverse_transform(y_valid.values.reshape(-1, 1)).flatten()\n",
    "y_test_orig = scaler.inverse_transform(y_test.values.reshape(-1, 1)).flatten()\n",
    "\n",
    "# Step 6: Calculate and print performance metrics on the original scale\n",
    "def print_metrics(y_true, y_pred, dataset_name):\n",
    "    print(f\"{dataset_name} Performance Metrics:\")\n",
    "    print(\"Mean Absolute Error (MAE): \", mean_absolute_error(y_true, y_pred))\n",
    "    print(\"Mean Squared Error (MSE): \", mean_squared_error(y_true, y_pred))\n",
    "    print(\"R-squared (R2): \", r2_score(y_true, y_pred))\n",
    "    print()\n",
    "\n",
    "# Print metrics for training, validation, and test data\n",
    "print(\"Performance with loaded model:\")\n",
    "print_metrics(y_train_orig, y_train_pred, \"Training\")\n",
    "print_metrics(y_valid_orig, y_valid_pred, \"Validation\")\n",
    "print_metrics(y_test_orig, y_test_pred, \"Test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "517f8bdb",
   "metadata": {},
   "source": [
    "## Lasso Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd331b2",
   "metadata": {},
   "source": [
    "## Without LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d9410a",
   "metadata": {},
   "source": [
    "#### Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b8380fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Excluded columns for scaling\n",
    "excluded_columns = ['id', 'host_id', 'longitude', 'latitude', 'date']\n",
    "\n",
    "# Prepare the data by dropping unnecessary columns and separating features and target\n",
    "def prepare_data(data, target_column):\n",
    "    X = data.drop(columns=['id', 'host_id', 'date', target_column])\n",
    "    y = data[target_column]\n",
    "    return X, y\n",
    "\n",
    "# Scale the features and the target variable\n",
    "def scale_features_and_target(X, y, excluded_columns):\n",
    "    numerical_features = X.select_dtypes(include=['float64', 'int64']).columns.difference(excluded_columns)\n",
    "    scaler = RobustScaler()\n",
    "    X_scaled = X.copy()\n",
    "    X_scaled[numerical_features] = scaler.fit_transform(X[numerical_features])\n",
    "    y_scaled = scaler.fit_transform(y.values.reshape(-1, 1)).flatten()\n",
    "    return X_scaled, y_scaled, scaler\n",
    "\n",
    "# Prepare the training, validation, and test sets\n",
    "X_train_raw, y_train_raw = prepare_data(train_data_london, 'price')\n",
    "X_valid_raw, y_valid_raw = prepare_data(valid_data_london, 'price')\n",
    "X_test_raw, y_test_raw = prepare_data(test_data_london, 'price')\n",
    "\n",
    "# Apply scaling to both features and target\n",
    "X_train_scaled, y_train_scaled, scaler = scale_features_and_target(X_train_raw, y_train_raw, excluded_columns)\n",
    "X_valid_scaled, y_valid_scaled, _ = scale_features_and_target(X_valid_raw, y_valid_raw, excluded_columns)\n",
    "X_test_scaled, y_test_scaled, _ = scale_features_and_target(X_test_raw, y_test_raw, excluded_columns)\n",
    "\n",
    "# Function to optimize using Optuna\n",
    "def objective(trial):\n",
    "    param = {\n",
    "        'alpha': trial.suggest_float('alpha', 0.0001, 1.0, log=True)\n",
    "    }\n",
    "\n",
    "    model = Lasso(**param)\n",
    "    model.fit(X_train_scaled, y_train_scaled)\n",
    "    preds = model.predict(X_valid_scaled)\n",
    "    mse = mean_squared_error(y_valid_scaled, preds)\n",
    "    return mse\n",
    "\n",
    "# Create a study\n",
    "study = optuna.create_study(direction='minimize', sampler=TPESampler())\n",
    "study.optimize(objective, n_trials=50, show_progress_bar=True)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params = study.best_params\n",
    "print(\"Best hyperparameters: \", best_params)\n",
    "\n",
    "# Train the model with the best hyperparameters\n",
    "best_model = Lasso(**best_params)\n",
    "best_model.fit(X_train_scaled, y_train_scaled)\n",
    "\n",
    "# Predict on the training, validation, and test sets with the best model\n",
    "y_train_pred_scaled = best_model.predict(X_train_scaled)\n",
    "y_valid_pred_scaled = best_model.predict(X_valid_scaled)\n",
    "y_test_pred_scaled = best_model.predict(X_test_scaled)\n",
    "\n",
    "# Inverse transform the scaled predictions and actual target values\n",
    "y_train_pred = scaler.inverse_transform(y_train_pred_scaled.reshape(-1, 1)).flatten()\n",
    "y_valid_pred = scaler.inverse_transform(y_valid_pred_scaled.reshape(-1, 1)).flatten()\n",
    "y_test_pred = scaler.inverse_transform(y_test_pred_scaled.reshape(-1, 1)).flatten()\n",
    "y_train_orig = scaler.inverse_transform(y_train_scaled.reshape(-1, 1)).flatten()\n",
    "y_valid_orig = scaler.inverse_transform(y_valid_scaled.reshape(-1, 1)).flatten()\n",
    "y_test_orig = scaler.inverse_transform(y_test_scaled.reshape(-1, 1)).flatten()\n",
    "\n",
    "# Calculate performance metrics on the original scale\n",
    "def print_metrics(y_true, y_pred, dataset_name):\n",
    "    print(f\"{dataset_name} Performance Metrics:\")\n",
    "    print(\"Mean Absolute Error (MAE): \", mean_absolute_error(y_true, y_pred))\n",
    "    print(\"Mean Squared Error (MSE): \", mean_squared_error(y_true, y_pred))\n",
    "    print(\"R-squared (R2): \", r2_score(y_true, y_pred))\n",
    "    print()\n",
    "\n",
    "# Print metrics for training, validation, and test data\n",
    "print(\"Performance with tuned hyperparameters:\")\n",
    "print_metrics(y_train_orig, y_train_pred, \"Training\")\n",
    "print_metrics(y_valid_orig, y_valid_pred, \"Validation\")\n",
    "print_metrics(y_test_orig, y_test_pred, \"Test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8155aa8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the model\n",
    "joblib.dump(best_model, 'lasso_model_without_lstm_london.joblib')\n",
    "\n",
    "# Load the model\n",
    "loaded_model = joblib.load('lasso_model_without_lstm_london.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7bd4e339",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance with loaded model:\n",
      "Training Performance Metrics:\n",
      "Mean Absolute Error (MAE):  55.97888690547539\n",
      "Mean Squared Error (MSE):  10088.88569875979\n",
      "R-squared (R2):  0.506141338418117\n",
      "\n",
      "Validation Performance Metrics:\n",
      "Mean Absolute Error (MAE):  60.079640738102164\n",
      "Mean Squared Error (MSE):  11845.046662639494\n",
      "R-squared (R2):  0.44295179415870145\n",
      "\n",
      "Test Performance Metrics:\n",
      "Mean Absolute Error (MAE):  60.64525213754897\n",
      "Mean Squared Error (MSE):  13890.289848297214\n",
      "R-squared (R2):  0.4618377799351169\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Step 1: Load the scaled datasets\n",
    "scaled_train_df = pd.read_csv('scaled_train_data_without_LSTM.csv')\n",
    "scaled_valid_df = pd.read_csv('scaled_valid_data_without_LSTM.csv')\n",
    "scaled_test_df = pd.read_csv('scaled_test_data_without_LSTM.csv')\n",
    "\n",
    "# Separate features and target from the scaled datasets\n",
    "X_train = scaled_train_df.drop(columns=['price'])\n",
    "y_train = scaled_train_df['price']\n",
    "X_valid = scaled_valid_df.drop(columns=['price'])\n",
    "y_valid = scaled_valid_df['price']\n",
    "X_test = scaled_test_df.drop(columns=['price'])\n",
    "y_test = scaled_test_df['price']\n",
    "\n",
    "# Step 2: Load the scaler\n",
    "scaler = joblib.load('scaler_without_LSTM.pkl')\n",
    "\n",
    "# Step 3: Load the saved model\n",
    "loaded_model = joblib.load('lasso_model_without_lstm_london.joblib')\n",
    "\n",
    "# Step 4: Make predictions using the loaded model\n",
    "y_train_pred_scaled = loaded_model.predict(X_train)\n",
    "y_valid_pred_scaled = loaded_model.predict(X_valid)\n",
    "y_test_pred_scaled = loaded_model.predict(X_test)\n",
    "\n",
    "# Step 5: Inverse transform the scaled predictions and actual target values\n",
    "y_train_pred = scaler.inverse_transform(y_train_pred_scaled.reshape(-1, 1)).flatten()\n",
    "y_valid_pred = scaler.inverse_transform(y_valid_pred_scaled.reshape(-1, 1)).flatten()\n",
    "y_test_pred = scaler.inverse_transform(y_test_pred_scaled.reshape(-1, 1)).flatten()\n",
    "y_train_orig = scaler.inverse_transform(y_train.values.reshape(-1, 1)).flatten()\n",
    "y_valid_orig = scaler.inverse_transform(y_valid.values.reshape(-1, 1)).flatten()\n",
    "y_test_orig = scaler.inverse_transform(y_test.values.reshape(-1, 1)).flatten()\n",
    "\n",
    "# Step 6: Calculate and print performance metrics on the original scale\n",
    "def print_metrics(y_true, y_pred, dataset_name):\n",
    "    print(f\"{dataset_name} Performance Metrics:\")\n",
    "    print(\"Mean Absolute Error (MAE): \", mean_absolute_error(y_true, y_pred))\n",
    "    print(\"Mean Squared Error (MSE): \", mean_squared_error(y_true, y_pred))\n",
    "    print(\"R-squared (R2): \", r2_score(y_true, y_pred))\n",
    "    print()\n",
    "\n",
    "# Print metrics for training, validation, and test data\n",
    "print(\"Performance with loaded model:\")\n",
    "print_metrics(y_train_orig, y_train_pred, \"Training\")\n",
    "print_metrics(y_valid_orig, y_valid_pred, \"Validation\")\n",
    "print_metrics(y_test_orig, y_test_pred, \"Test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1856bdf4",
   "metadata": {},
   "source": [
    "## With LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f18b231b",
   "metadata": {},
   "source": [
    "#### hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d72c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Excluded columns for scaling\n",
    "excluded_columns = ['id', 'host_id', 'longitude', 'latitude', 'date']\n",
    "\n",
    "# Prepare the data by dropping unnecessary columns and separating features and target\n",
    "def prepare_data(data, target_column):\n",
    "    X = data.drop(columns=['id', 'host_id', 'date', target_column])\n",
    "    y = data[target_column]\n",
    "    return X, y\n",
    "\n",
    "# Scale the features and the target variable\n",
    "def scale_features_and_target(X, y, excluded_columns):\n",
    "    numerical_features = X.select_dtypes(include=['float64', 'int64']).columns.difference(excluded_columns)\n",
    "    scaler = RobustScaler()\n",
    "    X_scaled = X.copy()\n",
    "    X_scaled[numerical_features] = scaler.fit_transform(X[numerical_features])\n",
    "    y_scaled = scaler.fit_transform(y.values.reshape(-1, 1)).flatten()\n",
    "    return X_scaled, y_scaled, scaler\n",
    "\n",
    "# Prepare the training, validation, and test sets\n",
    "X_train_raw, y_train_raw = prepare_data(train_data_lstm_london, 'price')\n",
    "X_valid_raw, y_valid_raw = prepare_data(valid_data_lstm_london, 'price')\n",
    "X_test_raw, y_test_raw = prepare_data(test_data_lstm_london, 'price')\n",
    "\n",
    "# Apply scaling to both features and target\n",
    "X_train_scaled, y_train_scaled, scaler = scale_features_and_target(X_train_raw, y_train_raw, excluded_columns)\n",
    "X_valid_scaled, y_valid_scaled, _ = scale_features_and_target(X_valid_raw, y_valid_raw, excluded_columns)\n",
    "X_test_scaled, y_test_scaled, _ = scale_features_and_target(X_test_raw, y_test_raw, excluded_columns)\n",
    "\n",
    "# Function to optimize using Optuna\n",
    "def objective(trial):\n",
    "    param = {\n",
    "        'alpha': trial.suggest_float('alpha', 0.0001, 1.0, log=True)\n",
    "    }\n",
    "\n",
    "    model = Lasso(**param)\n",
    "    model.fit(X_train_scaled, y_train_scaled)\n",
    "    preds = model.predict(X_valid_scaled)\n",
    "    mse = mean_squared_error(y_valid_scaled, preds)\n",
    "    return mse\n",
    "\n",
    "# Create a study\n",
    "study = optuna.create_study(direction='minimize', sampler=TPESampler())\n",
    "study.optimize(objective, n_trials=50, show_progress_bar=True)\n",
    "\n",
    "# Get the best hyperparameters and train the final model\n",
    "best_params = study.best_params\n",
    "best_model = Lasso(**best_params)\n",
    "best_model.fit(X_train_scaled, y_train_scaled)\n",
    "\n",
    "# Predict on the training, validation, and test sets with the best model\n",
    "y_train_pred_scaled = best_model.predict(X_train_scaled)\n",
    "y_valid_pred_scaled = best_model.predict(X_valid_scaled)\n",
    "y_test_pred_scaled = best_model.predict(X_test_scaled)\n",
    "\n",
    "# Inverse transform the scaled predictions and actual target values\n",
    "y_train_pred = scaler.inverse_transform(y_train_pred_scaled.reshape(-1, 1)).flatten()\n",
    "y_valid_pred = scaler.inverse_transform(y_valid_pred_scaled.reshape(-1, 1)).flatten()\n",
    "y_test_pred = scaler.inverse_transform(y_test_pred_scaled.reshape(-1, 1)).flatten()\n",
    "y_train_orig = scaler.inverse_transform(y_train_scaled.reshape(-1, 1)).flatten()\n",
    "y_valid_orig = scaler.inverse_transform(y_valid_scaled.reshape(-1, 1)).flatten()\n",
    "y_test_orig = scaler.inverse_transform(y_test_scaled.reshape(-1, 1)).flatten()\n",
    "\n",
    "# Calculate performance metrics on the original scale\n",
    "def print_metrics(y_true, y_pred, dataset_name):\n",
    "    print(f\"{dataset_name} Performance Metrics:\")\n",
    "    print(\"Mean Absolute Error (MAE): \", mean_absolute_error(y_true, y_pred))\n",
    "    print(\"Mean Squared Error (MSE): \", mean_squared_error(y_true, y_pred))\n",
    "    print(\"R-squared (R2): \", r2_score(y_true, y_pred))\n",
    "    print()\n",
    "\n",
    "# Print metrics for training, validation, and test data\n",
    "print_metrics(y_train_orig, y_train_pred, \"Training\")\n",
    "print_metrics(y_valid_orig, y_valid_pred, \"Validation\")\n",
    "print_metrics(y_test_orig, y_test_pred, \"Test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8cc86ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the model\n",
    "joblib.dump(best_model, 'lasso_model_with_lstm_london.joblib')\n",
    "\n",
    "# Load the model\n",
    "loaded_model = joblib.load('lasso_model_with_lstm_london.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ed6e9055",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance with loaded model:\n",
      "Training Performance Metrics:\n",
      "Mean Absolute Error (MAE):  12.29937104694274\n",
      "Mean Squared Error (MSE):  1050.8384095900278\n",
      "R-squared (R2):  0.9477268108929678\n",
      "\n",
      "Validation Performance Metrics:\n",
      "Mean Absolute Error (MAE):  9.552651850011259\n",
      "Mean Squared Error (MSE):  301.9017260571079\n",
      "R-squared (R2):  0.9857403854182493\n",
      "\n",
      "Test Performance Metrics:\n",
      "Mean Absolute Error (MAE):  21.24832392998566\n",
      "Mean Squared Error (MSE):  844.769048397836\n",
      "R-squared (R2):  0.9671280037474722\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Step 1: Load the scaled datasets\n",
    "scaled_train_df = pd.read_csv('scaled_train_data_with_LSTM.csv')\n",
    "scaled_valid_df = pd.read_csv('scaled_valid_data_with_LSTM.csv')\n",
    "scaled_test_df = pd.read_csv('scaled_test_data_with_LSTM.csv')\n",
    "\n",
    "# Separate features and target from the scaled datasets\n",
    "X_train = scaled_train_df.drop(columns=['price'])\n",
    "y_train = scaled_train_df['price']\n",
    "X_valid = scaled_valid_df.drop(columns=['price'])\n",
    "y_valid = scaled_valid_df['price']\n",
    "X_test = scaled_test_df.drop(columns=['price'])\n",
    "y_test = scaled_test_df['price']\n",
    "\n",
    "# Step 2: Load the scaler\n",
    "scaler = joblib.load('scaler_with_LSTM.pkl')\n",
    "\n",
    "# Step 3: Load the saved model\n",
    "loaded_model = joblib.load('lasso_model_with_lstm_london.joblib')\n",
    "\n",
    "# Step 4: Make predictions using the loaded model\n",
    "y_train_pred_scaled = loaded_model.predict(X_train)\n",
    "y_valid_pred_scaled = loaded_model.predict(X_valid)\n",
    "y_test_pred_scaled = loaded_model.predict(X_test)\n",
    "\n",
    "# Step 5: Inverse transform the scaled predictions and actual target values\n",
    "y_train_pred = scaler.inverse_transform(y_train_pred_scaled.reshape(-1, 1)).flatten()\n",
    "y_valid_pred = scaler.inverse_transform(y_valid_pred_scaled.reshape(-1, 1)).flatten()\n",
    "y_test_pred = scaler.inverse_transform(y_test_pred_scaled.reshape(-1, 1)).flatten()\n",
    "y_train_orig = scaler.inverse_transform(y_train.values.reshape(-1, 1)).flatten()\n",
    "y_valid_orig = scaler.inverse_transform(y_valid.values.reshape(-1, 1)).flatten()\n",
    "y_test_orig = scaler.inverse_transform(y_test.values.reshape(-1, 1)).flatten()\n",
    "\n",
    "# Step 6: Calculate and print performance metrics on the original scale\n",
    "def print_metrics(y_true, y_pred, dataset_name):\n",
    "    print(f\"{dataset_name} Performance Metrics:\")\n",
    "    print(\"Mean Absolute Error (MAE): \", mean_absolute_error(y_true, y_pred))\n",
    "    print(\"Mean Squared Error (MSE): \", mean_squared_error(y_true, y_pred))\n",
    "    print(\"R-squared (R2): \", r2_score(y_true, y_pred))\n",
    "    print()\n",
    "\n",
    "# Print metrics for training, validation, and test data\n",
    "print(\"Performance with loaded model:\")\n",
    "print_metrics(y_train_orig, y_train_pred, \"Training\")\n",
    "print_metrics(y_valid_orig, y_valid_pred, \"Validation\")\n",
    "print_metrics(y_test_orig, y_test_pred, \"Test\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

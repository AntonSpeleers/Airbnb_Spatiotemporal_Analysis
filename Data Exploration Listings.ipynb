{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbcd22b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the distributions of the review ratings columns\n",
    "variables_to_plot = list(dataframe1.columns[dataframe1.columns.str.startswith(\"review_scores\") == True])\n",
    "fig = plt.figure(figsize=(12,8))\n",
    "for i, var_name in enumerate(variables_to_plot):\n",
    "    ax = fig.add_subplot(3,3,i+1)\n",
    "    dataframe1[var_name].hist(bins=10,ax=ax)\n",
    "    ax.set_title(var_name)\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "#out of these we see that most of them are rated quite positive, with the biggest amount around 4-5/5 stars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ae7120",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the Paris neighbourhood  GeoJSON file as a dataframe in geopandas\n",
    "map_dataframe1 = gpd.read_file('C:/Users/anton/Documents/2de_master/Thesis/Code/analysis/Data/2. airbnb_data/Paris/Q1 airbnb_data Paris/neighbourhoods.geojson')\n",
    "map_dataframe1.drop('neighbourhood_group', axis = 1, inplace = True)\n",
    "map_dataframe1.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f3ede18",
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting the characteristics for the following plot\n",
    "plt.rcParams.update({'font.size': 30})\n",
    "plt.rcParams['figure.figsize'] = 280, 280\n",
    "\n",
    "\n",
    "# Creating a dataframe of listing counts and median price by neighbourhood\n",
    "neighbourhood_dataframe1 = pd.DataFrame(dataframe1.groupby('neighbourhood').size())\n",
    "neighbourhood_dataframe1.rename(columns={0: 'number_of_listings'}, inplace=True)\n",
    "neighbourhood_dataframe1['median_price'] = dataframe1.groupby('neighbourhood').price.median().values\n",
    "neighbourhood_dataframe1['mean_price'] = dataframe1.groupby('neighbourhood').price.mean().values\n",
    "\n",
    "# Putting the dataframes together\n",
    "neighbourhood_map_dataframe1 = map_dataframe1.set_index('neighbourhood').join(neighbourhood_dataframe1)\n",
    "                  \n",
    "# Plotting the number of listings in each neighbourhood\n",
    "fig1, ax1 = plt.subplots(1, figsize=(15, 6)) #deciding on plot size\n",
    "neighbourhood_map_dataframe1.plot(column='number_of_listings', cmap='Reds', ax=ax1, rasterized=True) \n",
    "#rasterized to makes it easier for big data sets + ax1 earlier defined\n",
    "\n",
    "ax1.axis('off') #disabling the axis components, including axis labels, ticks, and the frame surrounding the plot\n",
    "ax1.set_title('Amount of listings per neighbourhood in Paris', fontsize=14)\n",
    "cax1 = fig1.add_axes([0.9, 0.1, 0.03, 0.8]) # Adjusted the position and size as needed for the side axis [left, bottom, width, height]\n",
    "#ScalarMappable to make a color map + norm, to normalize the coloring within the graph \n",
    "sm1 = plt.cm.ScalarMappable(cmap='Reds', norm=plt.Normalize(vmin=0, vmax=9000))\n",
    "sm1._A = [] # The primary reason for doing this is to provide an empty array that will later be populated with the data range when the plot is created. The colorbar uses this array to decide the color scaling for the colormap.\n",
    "cbar1 = fig1.colorbar(sm1, cax=cax1) \n",
    "plt.show()\n",
    "\n",
    "# Plotting the median price of listings in each neighbourhood\n",
    "fig2, ax2 = plt.subplots(1, figsize=(15, 6))\n",
    "neighbourhood_map_dataframe1.plot(column='median_price', cmap='Reds', ax=ax2)\n",
    "ax2.axis('off')\n",
    "ax2.set_title('Median price per neighbourhood in Paris', fontsize=14)\n",
    "cax2 = fig2.add_axes([0.9, 0.1, 0.03, 0.8])  # Adjusted the position and size as needed for the side axis [left, bottom, width, height]\n",
    "#ScalarMappable to make a color map + norm, to normalize the coloring within the graph \n",
    "sm2 = plt.cm.ScalarMappable(cmap='Reds', norm=plt.Normalize(vmin=min(neighbourhood_map_dataframe1.median_price), vmax=max(neighbourhood_map_dataframe1.median_price))) \n",
    "sm2._A = [] # The primary reason for doing this is to provide an empty array that will later be populated with the data range when the plot is created. The colorbar uses this array to decide the color scaling for the colormap.\n",
    "cbar2 = fig2.colorbar(sm2, cax=cax2)\n",
    "plt.show()\n",
    "\n",
    "# Plotting the mean price of listings in each neighbourhood\n",
    "fig3, ax3 = plt.subplots(1, figsize=(15, 6))\n",
    "neighbourhood_map_dataframe1.plot(column='mean_price', cmap='Reds', ax=ax3)\n",
    "ax3.axis('off')\n",
    "ax3.set_title('Mean price per neighbourhood in Paris', fontsize=14)\n",
    "cax3 = fig3.add_axes([0.9, 0.1, 0.03, 0.8])  # Adjusted the position and size as needed for the side axis [left, bottom, width, height]\n",
    "#ScalarMappable to make a color map + norm, to normalize the coloring within the graph \n",
    "sm3 = plt.cm.ScalarMappable(cmap='Reds', norm=plt.Normalize(vmin=min(neighbourhood_map_dataframe1.mean_price), vmax=max(neighbourhood_map_dataframe1.mean_price))) \n",
    "sm3._A = [] # The primary reason for doing this is to provide an empty array that will later be populated with the data range when the plot is created. The colorbar uses this array to decide the color scaling for the colormap.\n",
    "cbar3 = fig3.colorbar(sm3, cax=cax3)\n",
    "plt.show()\n",
    "\n",
    "print(neighbourhood_dataframe1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b40cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot number of listings and median price in one bar plot\n",
    "plt.rcParams['font.size'] = 15\n",
    "plt.rcParams['figure.figsize'] = 25, 5\n",
    "selected_columns = ['number_of_listings', 'median_price']\n",
    "neighbourhood_dataframe1_selected = neighbourhood_dataframe1[selected_columns]\n",
    "neighbourhood_dataframe1_sorted = neighbourhood_dataframe1_selected.sort_values('median_price', ascending=False)\n",
    "neighbourhood_dataframe1_sorted.plot( kind= 'bar' , secondary_y= 'median_price' , rot= 90 )\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.show()\n",
    "\n",
    "# Plot number of listings and mean price in one bar plot\n",
    "plt.rcParams['font.size'] = 15\n",
    "plt.rcParams['figure.figsize'] = 25, 5\n",
    "selected_columns = ['number_of_listings', 'mean_price']\n",
    "neighbourhood_dataframe1_selected = neighbourhood_dataframe1[selected_columns]\n",
    "neighbourhood_dataframe1_sorted = neighbourhood_dataframe1_selected.sort_values('mean_price', ascending=False)\n",
    "neighbourhood_dataframe1_sorted.plot( kind= 'bar' , secondary_y= 'mean_price' , rot= 90 )\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739b6c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_count_and_price_plot(column_name,alpha=0.05):\n",
    "    # Assuming dataframe1 is your DataFrame\n",
    "\n",
    "    # Plot count distribution\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    sns.countplot(x=column_name, data=dataframe1)\n",
    "    plt.title(f'Count distribution of {column_name}')\n",
    "\n",
    "    # Plot median price distribution\n",
    "    plt.subplot(1, 2, 2)\n",
    "    median_prices = dataframe1.groupby(column_name)['price'].median()\n",
    "    median_prices.plot(kind='bar', color=['blue', 'orange'])\n",
    "    plt.title(f'Median price distribution by {column_name}')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Calculate t-test for median prices\n",
    "    true_prices = dataframe1[dataframe1[column_name] == True]['price']\n",
    "    false_prices = dataframe1[dataframe1[column_name] == False]['price']\n",
    "    t_stat, p_value = ttest_ind(true_prices, false_prices)\n",
    "   \n",
    "    # Display additional information\n",
    "    percent_split = dataframe1[column_name].value_counts(normalize=True) * 100\n",
    "    print(f'% Wise Split of {column_name}:\\n{percent_split}')\n",
    "    t_statistic, p_value = ttest_ind(true_prices, false_prices, equal_var=False)  # assuming unequal variances\n",
    "    print(f'\\nP-value for {column_name}: {p_value}')\n",
    "    \n",
    "    # Check if p-value is greater than or equal to alpha\n",
    "    if p_value >= alpha:\n",
    "        print(f\"{column_name} is not statistically significant (p-value >= {alpha})\")\n",
    "        return column_name\n",
    "    else:\n",
    "        print(f\"{column_name} is statistically significant (p-value < {alpha})\")\n",
    "        return None  # or any other value if needed\n",
    "\n",
    "superhost = binary_count_and_price_plot('host_is_superhost')\n",
    "print(dataframe1.host_is_superhost.value_counts(normalize=True))\n",
    "\n",
    "test2 = binary_count_and_price_plot('host_identity_verified')\n",
    "print(dataframe1.host_identity_verified.value_counts(normalize=True))\n",
    "\n",
    "test3 = binary_count_and_price_plot('instant_bookable')\n",
    "print(dataframe1.instant_bookable.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e2066c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get column names and their indices\n",
    "column_info = list(enumerate(dataframe1.columns))\n",
    "# Print column names and their indices\n",
    "for index, column_name in column_info:\n",
    "    print(f\"Column {index}: {column_name}\")\n",
    "    \n",
    "#now we know that the amenity columns start from index 51"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d8da5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#doing the analysis for all the different amenities\n",
    "plt.rcParams['font.size'] = 14\n",
    "plt.rcParams['figure.figsize'] = 20, 20\n",
    "result = [binary_count_and_price_plot(col) for col in dataframe1.iloc[:,51:-2].columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7df0f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now we are making a comparison against the rating and seeing if having the amenity might impact the rating\n",
    "\n",
    "def binary_count_and_rating_plot(column_name,alpha=0.05):\n",
    "    # Only taking the ones with reviews into consideration\n",
    "    data = dataframe1[[column_name, 'review_scores_rating']].dropna()\n",
    "\n",
    "    # Plot count distribution\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    sns.countplot(x=column_name, data=data)\n",
    "    plt.title(f'Count distribution of {column_name}')\n",
    "\n",
    "    # Plot median price distribution\n",
    "    plt.subplot(1, 2, 2)\n",
    "    rating_mean = data.groupby(column_name)['review_scores_rating'].mean()\n",
    "    rating_mean.plot(kind='bar', color=['blue', 'orange'])\n",
    "    plt.title(f'Average rating distribution by {column_name}')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Calculate t-test for median prices\n",
    "    true_ratings = data[data[column_name] == True]['review_scores_rating']\n",
    "    false_ratings = data[data[column_name] == False]['review_scores_rating']\n",
    "    t_stat, p_value = ttest_ind(true_ratings, false_ratings)\n",
    "   \n",
    "    # Display additional information\n",
    "    percent_split = data[column_name].value_counts(normalize=True) * 100\n",
    "    print(f'% Wise Split of {column_name}:\\n{percent_split}')\n",
    "    t_statistic, p_value = ttest_ind(true_ratings, false_ratings, equal_var=False)  # assuming unequal variances\n",
    "    print(f'\\nP-value for {column_name}: {p_value}')\n",
    "    \n",
    "    # Check if p-value is greater than or equal to alpha\n",
    "    if p_value >= alpha:\n",
    "        print(f\"{column_name} is not statistically significant (p-value >= {alpha})\")\n",
    "        return column_name\n",
    "    else:\n",
    "        print(f\"{column_name} is statistically significant (p-value < {alpha})\")\n",
    "        return None  # or any other value if needed\n",
    "    \n",
    "plt.rcParams['font.size'] = 14\n",
    "plt.rcParams['figure.figsize'] = 20, 20\n",
    "result = [binary_count_and_rating_plot(col) for col in dataframe1.iloc[:,51:-2].columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2609d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "def collect_pvalues(columns_of_interest):\n",
    "    all_pvalues = {}\n",
    "\n",
    "    for column_name in columns_of_interest:\n",
    "        # Drop rows with missing values in the specified columns\n",
    "        data = dataframe1[[column_name, 'price']].dropna()\n",
    "\n",
    "        # Calculate t-test for median prices\n",
    "        true_prices = data[data[column_name] == True]['price']\n",
    "        false_prices = data[data[column_name] == False]['price']\n",
    "        t_statistic, p_value = ttest_ind(true_prices, false_prices, equal_var=False)  # assuming unequal variances\n",
    "        all_pvalues[column_name] = {'p_value': p_value, 't_statistic': t_statistic}\n",
    "\n",
    "    return all_pvalues\n",
    "\n",
    "columns_of_interest = dataframe1.iloc[:, 51:-2].columns.values\n",
    "result = collect_pvalues(columns_of_interest)\n",
    "# Extract p-values and create a dictionary\n",
    "\n",
    "all_pvalues = {}\n",
    "for column in result:\n",
    "    p_value = result[column]['p_value']\n",
    "    if isinstance(p_value, np.float64):\n",
    "        all_pvalues[column] = p_value\n",
    "    else:\n",
    "        all_pvalues[column] = [float(val) for val in p_value]\n",
    "\n",
    "import math\n",
    "#P-values of effects of each amanity on price can be visualized using the 'Manhattan-plot' approach: taking the minus log of the P-value:\n",
    "# -log Pvalues and order\n",
    "all_pvalues.update({k: -1*np.log(v) for k, v in all_pvalues.items()})\n",
    "ordereddict = OrderedDict(sorted(all_pvalues.items(), key=lambda t: t[1]))\n",
    "plt.rcParams['font.size'] = 10\n",
    "plt.rcParams['figure.figsize'] = 12, 30\n",
    "plt.barh(list(ordereddict.keys()), list(ordereddict.values()),color='g', height=0.6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f14120e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['font.size'] = 14\n",
    "plt.rcParams['figure.figsize'] = 16, 8\n",
    "\n",
    "print(f\"Of the Airbnb hosts that are still listing on the site, the first joined on {min(dataframe1.host_since).strftime('%d %B %Y')}, and the most recent joined on {max(dataframe1.host_since).strftime('%d %B %Y')}.\")\n",
    "\n",
    "\n",
    "dataframe1.set_index('host_since').resample('MS').size().plot(label='Hosts joining Airbnb', color='orange')\n",
    "dataframe1.set_index('first_review').resample('MS').size().plot(label='Listings getting their first review', color='green')\n",
    "plt.title('Paris hosts registration on Airbnb, numbers of first reviews per accommodation per month')\n",
    "plt.legend()\n",
    "plt.xlim('2008-01-01', '2019-11-30') # Limiting to whole months\n",
    "plt.xlabel('')\n",
    "plt.ylabel('')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc95f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "\n",
    "def decompose_time_series(ts, title=''):\n",
    "    decomposition = seasonal_decompose(ts)\n",
    "    trend = decomposition.trend\n",
    "    seasonal = decomposition.seasonal\n",
    "    residual = decomposition.resid\n",
    "\n",
    "    plt.figure(figsize=(12, 8))\n",
    "\n",
    "    plt.subplot(411)\n",
    "    plt.plot(ts, label='Original')\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.title(f'{title} - Original')\n",
    "\n",
    "    plt.subplot(412)\n",
    "    plt.plot(trend, label='Trend')\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.title(f'{title} - Trend')\n",
    "\n",
    "    plt.subplot(413)\n",
    "    plt.plot(seasonal, label='Seasonal')\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.title(f'{title} - Seasonal')\n",
    "\n",
    "    plt.subplot(414)\n",
    "    plt.plot(residual, label='Residual')\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.title(f'{title} - Residual')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "# Creating dataframes for time series analysis\n",
    "ts_host_since = pd.DataFrame(dataframe1.set_index('host_since').resample('MS').size())\n",
    "ts_first_review = pd.DataFrame(dataframe1.set_index('first_review').resample('MS').size())\n",
    "\n",
    "# Renaming columns\n",
    "ts_host_since = ts_host_since.rename(columns={0: 'hosts'})\n",
    "ts_host_since.index.rename('month', inplace=True)\n",
    "ts_first_review = ts_first_review.rename(columns={0: 'reviews'})\n",
    "ts_first_review.index.rename('month', inplace=True)\n",
    "\n",
    "plt.rcParams['font.size'] = 12\n",
    "plt.rcParams['figure.figsize'] = 50, 70\n",
    "decompose_time_series(ts_host_since, title='Number of registrations on Airbnb by month')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e24998d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(dataframe1['reviews_per_month'].dropna(), bins=50, kde=True)\n",
    "plt.xlabel('Reviews Per Month')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Reviews Per Month Distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d24fe637",
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium\n",
    "from folium.plugins import HeatMap\n",
    "\n",
    "# Create a base map using the mean latitude and longitude values\n",
    "mean_lat = dataframe1['latitude'].mean()\n",
    "mean_lon = dataframe1['longitude'].mean()\n",
    "\n",
    "m = folium.Map(location=[mean_lat, mean_lon], zoom_start=12)\n",
    "\n",
    "# Create a HeatMap layer with price as the intensity\n",
    "heat_data = [[row['latitude'], row['longitude'], row['price']] for index, row in dataframe1.iterrows()]\n",
    "HeatMap(heat_data, radius=15, blur=10).add_to(m)\n",
    "\n",
    "# Display the map in Jupyter Notebook\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5682ff06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding out the neighborhoods that correspond with the rules we've established.\n",
    "top_6 = (dataframe1.groupby(['neighbourhood'])['id'].count()\n",
    "        .sort_values(ascending = False).head(6))\n",
    "\n",
    "# Let's make a list containing all the 'top_6' Series neighborhoods.\n",
    "desirable_neighborhoods = list(top_6.index)\n",
    "\n",
    "# Here, we'll perform a group by. It will list all neighborhoods \n",
    "# and their property types available. Also, it will count the number of \n",
    "# dwellings each residence kind has.\n",
    "property_types_count = dataframe1.groupby(['neighbourhood','property_type'], as_index = False)['id'].count()\n",
    "property_types_count = (property_types_count.sort_values(by = 'id', ascending = False)) \n",
    "\n",
    "# Let's make a list containing all the 'top_6' Series neighborhoods.\n",
    "desirable_neighborhoods = list(top_6.index)\n",
    "\n",
    "# We'll  filter the DF so that it only contains residences registered \n",
    "# in the 'desirable_neighborhoods' list.\n",
    "property_types_count = (property_types_count[property_types_count['neighbourhood']\n",
    "                                             .isin(desirable_neighborhoods)])\n",
    "\n",
    "# And that's it! We are set to plot the chart!\n",
    "import plotly.express as px\n",
    "\n",
    "# Unfortunately plotly has a bug for the sunburst plot \n",
    "# in which it does not recognize the 'id' column for the chart creation. \n",
    "\n",
    "# Hence we'll have to make a second column with the same data.\n",
    "# We are going to call the new column 'Number of Dwellings'\n",
    "property_types_count['Number of Dwellings'] = property_types_count['id']\n",
    "\n",
    "# Finally plotting the sunburst chart!\n",
    "figure = px.sunburst(property_types_count, values = 'Number of Dwellings', \n",
    "                     path = ['neighbourhood','property_type'], width = 600, height = 600, \n",
    "                     title = 'Dwelling Type Composition')\n",
    "\n",
    "figure.update_traces(textinfo=\"label+percent parent\")\n",
    "figure.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb762e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Cut the 'review_scores_value' into categories\n",
    "categories = pd.cut(dataframe1['review_scores_value'].dropna(), 4, labels=['Poor', 'Average', 'Good', 'Excellent'])\n",
    "dataframe1['Lodging Quality'] = categories\n",
    "\n",
    "# Filter out residences with no customer evaluation\n",
    "no_nan = dataframe1[~dataframe1['review_scores_value'].isnull()]\n",
    "\n",
    "# Set seaborn style\n",
    "sns.set(style='whitegrid')\n",
    "\n",
    "# Group by 'Lodging Quality' and calculate the average price for each category\n",
    "groups = no_nan.groupby('Lodging Quality')['price'].mean()\n",
    "\n",
    "# Set the figure size\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "# Plot the bar chart with adjusted ylim\n",
    "chart = groups.plot(kind='bar', ylim=(0, 300), xlabel='', yticks=[], fontsize=12, color=['grey', 'grey', 'darkred', 'grey'])\n",
    "\n",
    "# Display average prices on top of the bars\n",
    "for i, price in enumerate(groups):\n",
    "    plt.text(i, price + 10, f'${price:.2f}', ha='center', va='bottom', fontdict={'size': 12})\n",
    "\n",
    "# Set the graph title\n",
    "plt.title('Average Price per Dwelling Quality', fontdict={'size': 15})\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50980ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#showing the distribution between price and amount of bedrooms\n",
    "figsize = (10, 5)\n",
    "x = 'bedrooms'\n",
    "\n",
    "# Create a grid with 2 rows and 1 column\n",
    "fig = plt.figure(figsize=figsize)\n",
    "gs = gridspec.GridSpec(1, 1)\n",
    "\n",
    "# Bar plot for price distribution\n",
    "ax1 = plt.subplot(gs[0])\n",
    "sns.barplot(data=dataframe1, x=x, y='price', ax=ax1)\n",
    "ax1.set_title(f'Distribution of Price based on {x}')\n",
    "\n",
    "# Calculate the percentage of each bedroom count relative to all listings\n",
    "bedroom_percentage = dataframe1[x].value_counts(normalize=True) * 100\n",
    "\n",
    "# Display the percentage of each bedroom count\n",
    "for bedrooms, percentage in bedroom_percentage.items():\n",
    "    print(f'The percentage of listings with {bedrooms} bedroom(s) is: {percentage:.2f}%')\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50922cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#showing the distribution between price and amount of beds\n",
    "figsize = (10, 5)\n",
    "x = 'beds'\n",
    "\n",
    "# Create a grid with 2 rows and 1 column\n",
    "fig = plt.figure(figsize=figsize)\n",
    "gs = gridspec.GridSpec(1, 1)\n",
    "\n",
    "# Bar plot for price distribution\n",
    "ax1 = plt.subplot(gs[0])\n",
    "sns.barplot(data=dataframe1, x=x, y='price', ax=ax1)\n",
    "ax1.set_title(f'Distribution of Price based on {x}')\n",
    "\n",
    "# Calculate the percentage of each bedroom count relative to all listings\n",
    "bed_percentage = dataframe1[x].value_counts(normalize=True) * 100\n",
    "\n",
    "# Display the percentage of each bedroom count\n",
    "for beds, percentage in bed_percentage.items():\n",
    "    print(f'The percentage of listings with {beds} bed(s) is: {percentage:.2f}%')\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c32a9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#showing the distribution between price and amount of bathrooms\n",
    "figsize = (10, 5)\n",
    "x = 'bathrooms'\n",
    "\n",
    "# Create a grid with 2 rows and 1 column\n",
    "fig = plt.figure(figsize=figsize)\n",
    "gs = gridspec.GridSpec(1, 1)\n",
    "\n",
    "# Bar plot for price distribution\n",
    "ax1 = plt.subplot(gs[0])\n",
    "sns.barplot(data=dataframe1, x=x, y='price', ax=ax1)\n",
    "ax1.set_title(f'Distribution of Price based on {x}')\n",
    "\n",
    "# Calculate the percentage of each bedroom count relative to all listings\n",
    "bathroom_percentage = dataframe1[x].value_counts(normalize=True) * 100\n",
    "\n",
    "# Display the percentage of each bedroom count\n",
    "for bathrooms, percentage in bathroom_percentage.items():\n",
    "    print(f'The percentage of listings with {bathrooms} bathroom(s) is: {percentage:.2f}%')\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17cfdf4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#showing the distribution between price and amount of bathrooms\n",
    "figsize = (10, 5)\n",
    "x = 'room_type'\n",
    "\n",
    "# Create a grid with 2 rows and 1 column\n",
    "fig = plt.figure(figsize=figsize)\n",
    "gs = gridspec.GridSpec(1, 1)\n",
    "\n",
    "# Bar plot for price distribution\n",
    "ax1 = plt.subplot(gs[0])\n",
    "sns.barplot(data=dataframe1, x=x, y='price', ax=ax1)\n",
    "ax1.set_title(f'Distribution of Price based on {x}')\n",
    "\n",
    "# Calculate the percentage of each bedroom count relative to all listings\n",
    "room_type_percentage = dataframe1[x].value_counts(normalize=True) * 100\n",
    "\n",
    "# Display the percentage of each bedroom count\n",
    "for room_type, percentage in room_type_percentage.items():\n",
    "    print(f'The percentage of listings with {room_type} room type(s) is: {percentage:.2f}%')\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e765df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#showing the distribution between price and amount of bathrooms\n",
    "figsize = (10, 5)\n",
    "x = 'accommodates'\n",
    "\n",
    "# Create a grid with 2 rows and 1 column\n",
    "fig = plt.figure(figsize=figsize)\n",
    "gs = gridspec.GridSpec(1, 1)\n",
    "\n",
    "# Bar plot for price distribution\n",
    "ax1 = plt.subplot(gs[0])\n",
    "sns.barplot(data=dataframe1, x=x, y='price', ax=ax1)\n",
    "ax1.set_title(f'Distribution of Price based on {x}')\n",
    "\n",
    "# Calculate the percentage of each bedroom count relative to all listings\n",
    "accommodates_percentage = dataframe1[x].value_counts(normalize=True) * 100\n",
    "\n",
    "# Display the percentage of each bedroom count\n",
    "for accommodates, percentage in accommodates_percentage.items():\n",
    "    print(f'The percentage of listings with {accommodates} accommodates is: {percentage:.2f}%')\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34255e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the total number of amenities for each listing\n",
    "dataframe1['total_amenities'] = dataframe1.iloc[:, 51:-1].sum(axis=1)\n",
    "\n",
    "#showing the distribution between price and amount of bathrooms\n",
    "figsize = (10, 5)\n",
    "x = 'total_amenities'\n",
    "\n",
    "# Create a grid with 2 rows and 1 column\n",
    "fig = plt.figure(figsize=figsize)\n",
    "gs = gridspec.GridSpec(1, 1)\n",
    "\n",
    "# Bar plot for price distribution\n",
    "ax1 = plt.subplot(gs[0])\n",
    "sns.barplot(data=dataframe1, x=x, y='price', ax=ax1)\n",
    "ax1.set_title(f'Distribution of Price based on {x}')\n",
    "\n",
    "# Calculate the percentage of each bedroom count relative to all listings\n",
    "total_amenities_percentage = dataframe1[x].value_counts(normalize=True) * 100\n",
    "\n",
    "# Display the percentage of each bedroom count\n",
    "for total_amenities, percentage in total_amenities_percentage.items():\n",
    "    print(f'The percentage of listings with {total_amenities} total_amenities is: {percentage:.2f}%')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee33852a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from geopy.geocoders import Nominatim\n",
    "from sklearn.cluster import DBSCAN, KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import folium\n",
    "from folium.plugins import MarkerCluster\n",
    "\n",
    "#Trying to avoid the memory leak of kmeans KML\n",
    "os.environ['OMP_NUM_THREADS'] = '1'\n",
    "# Set up the map centered around Paris\n",
    "paris_map = folium.Map(location=[48.8566, 2.3522], zoom_start=12)\n",
    "# Add cluster centers to the map using MarkerCluster\n",
    "marker_cluster = MarkerCluster().add_to(paris_map)\n",
    "\n",
    "#making a new dataframe for the locations of the listings\n",
    "data = {\n",
    "    'latitude': dataframe1['latitude'].head(100).tolist(),\n",
    "    'longitude': dataframe1['longitude'].head(100).tolist(),\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Step 1: Reverse geocoding to extract postal codes and ranks\n",
    "geolocator = Nominatim(user_agent=\"geo_analyzer\")\n",
    "\n",
    "df['location'] = df.apply(lambda row: geolocator.reverse((row['latitude'], row['longitude'])), axis=1)\n",
    "df['rank'] = df['location'].apply(lambda loc: loc.raw.get('importance', None))\n",
    "\n",
    "def rank_to_color(rank):\n",
    "    if rank is not None:\n",
    "        rank = float(rank)  # Convert rank to float for better precision\n",
    "        if rank > 0.5:\n",
    "            return 'darkgreen'\n",
    "        elif 0.3 < rank <= 0.5:\n",
    "            return 'green'\n",
    "        elif 0.1 < rank <= 0.3:\n",
    "            return 'lightgreen'\n",
    "        elif 0.05 < rank <= 0.1:\n",
    "            return 'lightorange'\n",
    "        elif rank <= 0.05:\n",
    "            return 'darkorange'\n",
    "    return 'gray'\n",
    "\n",
    "# Step 3: KMeans Clustering with Euclidean distance metric\n",
    "your_desired_clusters = dataframe1['neighbourhood'].nunique()\n",
    "kmeans = KMeans(n_clusters=your_desired_clusters, n_init=10)\n",
    "df['cluster_kmeans'] = kmeans.fit_predict(df[['latitude', 'longitude']])\n",
    "\n",
    "# Calculate average rank for each cluster\n",
    "cluster_avg_rank = df.groupby('cluster_kmeans')['rank'].mean().to_dict()\n",
    "df['cluster_avg_rank'] = df['cluster_kmeans'].map(cluster_avg_rank)\n",
    "\n",
    "# Create a dictionary to store cluster information\n",
    "clusters_info = {}\n",
    "\n",
    "# Iterate through each row to populate the clusters_info dictionary\n",
    "for idx, row in df.iterrows():\n",
    "    cluster_label = row['cluster_kmeans']\n",
    "    \n",
    "    # If cluster_label is not in clusters_info, create an entry\n",
    "    if cluster_label not in clusters_info:\n",
    "        clusters_info[cluster_label] = {\n",
    "            'latitude_sum': row['latitude'],\n",
    "            'longitude_sum': row['longitude'],\n",
    "            'avg_rank': cluster_avg_rank[cluster_label],\n",
    "            'count': 1\n",
    "        }\n",
    "    else:\n",
    "        # Update sum of coordinates, average rank, and count for existing cluster\n",
    "        clusters_info[cluster_label]['latitude_sum'] += row['latitude']\n",
    "        clusters_info[cluster_label]['longitude_sum'] += row['longitude']\n",
    "        clusters_info[cluster_label]['avg_rank'] += cluster_avg_rank[cluster_label]\n",
    "        clusters_info[cluster_label]['count'] += 1\n",
    "\n",
    "# Add each cluster's information to the map\n",
    "for cluster_label, info in clusters_info.items():\n",
    "    # Calculate centroid (middle point) of the cluster\n",
    "    centroid_latitude = info['latitude_sum'] / info['count']\n",
    "    centroid_longitude = info['longitude_sum'] / info['count']\n",
    "    \n",
    "    color = rank_to_color(info['avg_rank'] / info['count'])  # Calculate average rank\n",
    "    folium.CircleMarker(\n",
    "        location=[centroid_latitude, centroid_longitude],\n",
    "        radius=10,  # Adjust the radius based on the count\n",
    "        color=color,\n",
    "        fill=True,\n",
    "        fill_color=color,\n",
    "        fill_opacity=0.7,\n",
    "        popup=f\"Avg Rank: {info['avg_rank'] / info['count']:.2f}, Cluster KMeans: {cluster_label}\"\n",
    "    ).add_to(paris_map)\n",
    "    \n",
    "# Plotting the cluster centers on the map of Paris\n",
    "paris_map\n",
    "\n",
    "#not yet to the point, so not accurate yet"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

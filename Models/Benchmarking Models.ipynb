{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d4aaf3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#insert file_path for the data\n",
    "file_path = 'C:/Users/anton/Documents/2de_master/Thesis/Code/analysis/Code/Airbnb_Spatiotemporal_Analysis/Paris Airbnb_Spatiotemporal_Analysis/Correlation analysis/FINAL_MERGED_DATASET.xlsx'\n",
    "data_copy= pd.read_excel(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3353ccef",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a8ef61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "X = data_copy.drop([\"price\"], axis=1)\n",
    "y = data_copy['price']\n",
    "\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a Random Forest model\n",
    "rf = RandomForestRegressor(random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate the model\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "#looking at MSE\n",
    "from sklearn.metrics import mean_squared_error\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"Mean Squared Error:, {mse:.4f}\")\n",
    "\n",
    "# Calculate R-squared\n",
    "from sklearn.metrics import r2_score\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f\"R-squared: {r2:.4f}\")\n",
    "\n",
    "# Calculate Adjusted R-squared\n",
    "n = X_test.shape[0]  # Number of observations\n",
    "p = X_test.shape[1]  # Number of predictor variables\n",
    "adjusted_r2 = 1 - (1 - r2) * (n - 1) / (n - p - 1)\n",
    "print(f\"Adjusted R-squared: {adjusted_r2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669a7480",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "X = data_copy.drop([\"price\"], axis=1)\n",
    "y = data_copy['price']\n",
    "\n",
    "original_features = data_copy.drop([\"price\"], axis=1).columns\n",
    "\n",
    "# Calculate feature importances\n",
    "importances = mutual_info_classif(X, y)\n",
    "feat_importances = pd.Series(importances, X.columns)\n",
    "\n",
    "# Set a threshold for feature importance (this is arbitrary and can be adjusted)\n",
    "threshold = 0.01  # Example threshold\n",
    "\n",
    "# Select features above the importance threshold\n",
    "selected_features = feat_importances[feat_importances > threshold].index\n",
    "\n",
    "# Rebuild the feature set with only selected features\n",
    "X_selected = X[selected_features]\n",
    "\n",
    "# Number of features dropped\n",
    "features_dropped = set(original_features) - set(selected_features)\n",
    "num_features_dropped = len(features_dropped)\n",
    "\n",
    "# Number of features remaining\n",
    "num_features_remaining = len(selected_features)\n",
    "\n",
    "# Print information about dropped and remaining features\n",
    "print(\"Features Dropped:\", features_dropped)\n",
    "print(\"Number of Features Dropped:\", num_features_dropped)\n",
    "print(\"Number of Features Remaining:\", num_features_remaining)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Train a Random Forest model\n",
    "rf = RandomForestRegressor(random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate the model\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "#looking at MSE\n",
    "from sklearn.metrics import mean_squared_error\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "\n",
    "# Calculate R-squared\n",
    "from sklearn.metrics import r2_score\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(\"R-squared:\", r2)\n",
    "\n",
    "# Calculate Adjusted R-squared\n",
    "n = X_test.shape[0]  # Number of observations\n",
    "p = X_test.shape[1]  # Number of predictor variables\n",
    "adjusted_r2 = 1 - (1 - r2) * (n - 1) / (n - p - 1)\n",
    "print(\"Adjusted R-squared:\", adjusted_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddce5c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Get unique ids\n",
    "all_ids = data_copy['id'].unique()\n",
    "\n",
    "# Split ids into training and testing sets\n",
    "train_ids, test_ids = train_test_split(all_ids, test_size=0.3, random_state=42)\n",
    "\n",
    "# Filter data based on selected ids\n",
    "train_selected = data_copy[data_copy['id'].isin(train_ids)]\n",
    "test_selected = data_copy[data_copy['id'].isin(test_ids)]\n",
    "\n",
    "# Define the time cutoff date\n",
    "cutoff_date = pd.to_datetime('2023-11-24')  # Example: YYYY-MM-DD\n",
    "\n",
    "# Convert 'day', 'month', 'year' to a unified date column in 'train_selected' and 'test_selected'\n",
    "train_selected['date'] = pd.to_datetime(train_selected[['year', 'month', 'day']])\n",
    "test_selected['date'] = pd.to_datetime(test_selected[['year', 'month', 'day']])\n",
    "\n",
    "# Now split the dataset based on the cutoff date\n",
    "train_data = train_selected[train_selected['date'] < cutoff_date]\n",
    "test_data = test_selected[test_selected['date'] >= cutoff_date]\n",
    "\n",
    "# Separate features and target variable for training and testing sets\n",
    "X_train = train_data.drop([\"price\", \"id\",\"date\"], axis=1)\n",
    "y_train = train_data['price']\n",
    "X_test = test_data.drop([\"price\", \"id\",\"date\"], axis=1)\n",
    "y_test = test_data['price']\n",
    "\n",
    "# Initialize and train the model\n",
    "model = RandomForestRegressor()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate the model\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model on the out-of-time testing data\n",
    "mse_score = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error (MSE):\", mse_score)\n",
    "\n",
    "# R-squared (R2) value calculated\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(\"R-squared (R2) Value:\", r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee1f2fa6",
   "metadata": {},
   "source": [
    "# Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f8dd22",
   "metadata": {},
   "source": [
    "## Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2b10dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pandas scikit-learn xgboost matplotlib\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Split the data into features (X) and target variable (y)\n",
    "X = data_copy.drop(['price'], axis=1)\n",
    "y = data_copy['price']\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Instantiate XGBoost Regressor\n",
    "model = LinearRegression()\n",
    "\n",
    "# Fit the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "#MSE value calculated \n",
    "mse_score = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error (MSE):\", mse_score)\n",
    "\n",
    "#r2_score calculated\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(\"R-squared (R2) Value:\", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0c91a968",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features Dropped: {'Mini fridge', 'gym', 'neighbourhood_Opéra', 'Blender', 'neighbourhood_Louvre', 'Board games', 'neighbourhood_Bourse', 'Breakfast', 'season_Autumn', 'is_school_holiday', 'neighbourhood_Entrepôt', 'neighbourhood_Hôtel-de-Ville', 'Rice maker', 'property_type_Other', 'neighbourhood_Gobelins', 'Radiant heating', 'Outdoor furniture', 'Outdoor dining area', 'pool', 'neighbourhood_Vaugirard', 'bbq', 'game console', 'sauna', 'weekday', 'neighbourhood_Panthéon', 'Bread maker', 'Piano', 'season_Winter', 'room_type_Shared room', 'neighbourhood_Batignolles-Monceau', 'day', 'exercise equipment', 'neighbourhood_Popincourt', 'Pets allowed', 'hot tub', 'Portable heater', 'season_Spring', 'neighbourhood_Palais-Bourbon', 'neighbourhood_Luxembourg', 'Sound system', 'neighbourhood_Observatoire', 'neighbourhood_Passy', 'is_holiday', 'season_Summer', 'neighbourhood_Buttes-Chaumont', 'neighbourhood_Reuilly', 'property_type_House', 'Cleaning available during stay'}\n",
      "Number of Features Dropped: 48\n",
      "Number of Features Remaining: 118\n",
      "Mean Squared Error: 23866.979180527753\n",
      "R-squared: 0.20184991090483184\n",
      "Adjusted R-squared: 0.1998808592330451\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "#X = data_copy.drop([\"price\"], axis=1)\n",
    "#y = data_copy['price']\n",
    "\n",
    "#original_features = data_copy.drop([\"price\"], axis=1).columns\n",
    "\n",
    "# Calculate feature importances\n",
    "#importances = mutual_info_classif(X, y)\n",
    "#feat_importances = pd.Series(importances, X.columns)\n",
    "\n",
    "# Set a threshold for feature importance (this is arbitrary and can be adjusted)\n",
    "#threshold = 0.01  # Example threshold\n",
    "\n",
    "# Select features above the importance threshold\n",
    "#selected_features = feat_importances[feat_importances > threshold].index\n",
    "\n",
    "# Rebuild the feature set with only selected features\n",
    "#X_selected = X[selected_features]\n",
    "\n",
    "# Number of features dropped\n",
    "#features_dropped = set(original_features) - set(selected_features)\n",
    "#num_features_dropped = len(features_dropped)\n",
    "\n",
    "# Number of features remaining\n",
    "#num_features_remaining = len(selected_features)\n",
    "\n",
    "# Print information about dropped and remaining features\n",
    "print(\"Features Dropped:\", features_dropped)\n",
    "print(\"Number of Features Dropped:\", num_features_dropped)\n",
    "print(\"Number of Features Remaining:\", num_features_remaining)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.3, random_state=42)\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Train a Random Forest model\n",
    "rf = LinearRegression()\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate the model\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "#looking at MSE\n",
    "from sklearn.metrics import mean_squared_error\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "\n",
    "# Calculate R-squared\n",
    "from sklearn.metrics import r2_score\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(\"R-squared:\", r2)\n",
    "\n",
    "# Calculate Adjusted R-squared\n",
    "n = X_test.shape[0]  # Number of observations\n",
    "p = X_test.shape[1]  # Number of predictor variables\n",
    "adjusted_r2 = 1 - (1 - r2) * (n - 1) / (n - p - 1)\n",
    "print(\"Adjusted R-squared:\", adjusted_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a56dbf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Get unique ids\n",
    "all_ids = data_copy['id'].unique()\n",
    "\n",
    "# Split ids into training and testing sets\n",
    "train_ids, test_ids = train_test_split(all_ids, test_size=0.3, random_state=42)\n",
    "\n",
    "# Filter data based on selected ids\n",
    "train_selected = data_copy[data_copy['id'].isin(train_ids)]\n",
    "test_selected = data_copy[data_copy['id'].isin(test_ids)]\n",
    "\n",
    "# Define the time cutoff date\n",
    "cutoff_date = pd.to_datetime('2023-11-24')  # Example: YYYY-MM-DD\n",
    "\n",
    "# Convert 'day', 'month', 'year' to a unified date column in 'train_selected' and 'test_selected'\n",
    "train_selected['date'] = pd.to_datetime(train_selected[['year', 'month', 'day']])\n",
    "test_selected['date'] = pd.to_datetime(test_selected[['year', 'month', 'day']])\n",
    "\n",
    "# Now split the dataset based on the cutoff date\n",
    "train_data = train_selected[train_selected['date'] < cutoff_date]\n",
    "test_data = test_selected[test_selected['date'] >= cutoff_date]\n",
    "\n",
    "# Separate features and target variable for training and testing sets\n",
    "X_train = train_data.drop([\"price\", \"id\",\"date\"], axis=1)\n",
    "y_train = train_data['price']\n",
    "X_test = test_data.drop([\"price\", \"id\",\"date\"], axis=1)\n",
    "y_test = test_data['price']\n",
    "\n",
    "# Initialize and train the model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate the model\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model on the out-of-time testing data\n",
    "mse_score = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error (MSE):\", mse_score)\n",
    "\n",
    "# R-squared (R2) value calculated\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(\"R-squared (R2) Value:\", r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0982618",
   "metadata": {},
   "source": [
    "## Ridge regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f0fd8ae1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 14704.7490201425\n",
      "R-squared (R2) Value: 0.5082495923856041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anton\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_ridge.py:211: LinAlgWarning: Ill-conditioned matrix (rcond=6.39716e-39): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n"
     ]
    }
   ],
   "source": [
    "#!pip install pandas scikit-learn xgboost matplotlib\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge  # Importing Ridge\n",
    "\n",
    "\n",
    "# Split the data into features (X) and target variable (y)\n",
    "X = data_copy.drop(['price'], axis=1)\n",
    "y = data_copy['price']\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Instantiate Ridge Regressor\n",
    "# You can adjust the alpha parameter as needed, which controls the strength of regularization\n",
    "model = Ridge(alpha=1.0)\n",
    "\n",
    "# Fit the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "#MSE value calculated \n",
    "mse_score = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error (MSE):\", mse_score)\n",
    "\n",
    "#r2_score calculated\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(\"R-squared (R2) Value:\", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9fe156f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features Dropped: {'Mini fridge', 'gym', 'neighbourhood_Opéra', 'Blender', 'neighbourhood_Louvre', 'Board games', 'neighbourhood_Bourse', 'Breakfast', 'season_Autumn', 'is_school_holiday', 'neighbourhood_Entrepôt', 'neighbourhood_Hôtel-de-Ville', 'Rice maker', 'property_type_Other', 'neighbourhood_Gobelins', 'Radiant heating', 'Outdoor furniture', 'Outdoor dining area', 'pool', 'neighbourhood_Vaugirard', 'bbq', 'game console', 'sauna', 'weekday', 'neighbourhood_Panthéon', 'Bread maker', 'Piano', 'season_Winter', 'room_type_Shared room', 'neighbourhood_Batignolles-Monceau', 'day', 'exercise equipment', 'neighbourhood_Popincourt', 'Pets allowed', 'hot tub', 'Portable heater', 'season_Spring', 'neighbourhood_Palais-Bourbon', 'neighbourhood_Luxembourg', 'Sound system', 'neighbourhood_Observatoire', 'neighbourhood_Passy', 'is_holiday', 'season_Summer', 'neighbourhood_Buttes-Chaumont', 'neighbourhood_Reuilly', 'property_type_House', 'Cleaning available during stay'}\n",
      "Number of Features Dropped: 48\n",
      "Number of Features Remaining: 118\n",
      "Mean Squared Error: 14856.67850287959\n",
      "R-squared: 0.5031688266437155\n",
      "Adjusted R-squared: 0.5019431345516405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anton\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_ridge.py:211: LinAlgWarning: Ill-conditioned matrix (rcond=1.36765e-38): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "#X = data_copy.drop([\"price\"], axis=1)\n",
    "#y = data_copy['price']\n",
    "\n",
    "#original_features = data_copy.drop([\"price\"], axis=1).columns\n",
    "\n",
    "# Calculate feature importances\n",
    "#importances = mutual_info_classif(X, y)\n",
    "#feat_importances = pd.Series(importances, X.columns)\n",
    "\n",
    "# Set a threshold for feature importance (this is arbitrary and can be adjusted)\n",
    "#threshold = 0.01  # Example threshold\n",
    "\n",
    "# Select features above the importance threshold\n",
    "#selected_features = feat_importances[feat_importances > threshold].index\n",
    "\n",
    "# Rebuild the feature set with only selected features\n",
    "#X_selected = X[selected_features]\n",
    "\n",
    "# Number of features dropped\n",
    "#features_dropped = set(original_features) - set(selected_features)\n",
    "#num_features_dropped = len(features_dropped)\n",
    "\n",
    "# Number of features remaining\n",
    "#num_features_remaining = len(selected_features)\n",
    "\n",
    "# Print information about dropped and remaining features\n",
    "print(\"Features Dropped:\", features_dropped)\n",
    "print(\"Number of Features Dropped:\", num_features_dropped)\n",
    "print(\"Number of Features Remaining:\", num_features_remaining)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Train a Random Forest model\n",
    "rf = Ridge(alpha=1.0)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate the model\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "#looking at MSE\n",
    "from sklearn.metrics import mean_squared_error\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "\n",
    "# Calculate R-squared\n",
    "from sklearn.metrics import r2_score\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(\"R-squared:\", r2)\n",
    "\n",
    "# Calculate Adjusted R-squared\n",
    "n = X_test.shape[0]  # Number of observations\n",
    "p = X_test.shape[1]  # Number of predictor variables\n",
    "adjusted_r2 = 1 - (1 - r2) * (n - 1) / (n - p - 1)\n",
    "print(\"Adjusted R-squared:\", adjusted_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "939ad6b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anton\\AppData\\Local\\Temp\\ipykernel_42556\\2496819068.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_selected['date'] = pd.to_datetime(train_selected[['year', 'month', 'day']])\n",
      "C:\\Users\\anton\\AppData\\Local\\Temp\\ipykernel_42556\\2496819068.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_selected['date'] = pd.to_datetime(test_selected[['year', 'month', 'day']])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 17005.61523358971\n",
      "R-squared (R2) Value: 0.4817484000656036\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Get unique ids\n",
    "all_ids = data_copy['id'].unique()\n",
    "\n",
    "# Split ids into training and testing sets\n",
    "train_ids, test_ids = train_test_split(all_ids, test_size=0.3, random_state=42)\n",
    "\n",
    "# Filter data based on selected ids\n",
    "train_selected = data_copy[data_copy['id'].isin(train_ids)]\n",
    "test_selected = data_copy[data_copy['id'].isin(test_ids)]\n",
    "\n",
    "# Define the time cutoff date\n",
    "cutoff_date = pd.to_datetime('2023-11-24')  # Example: YYYY-MM-DD\n",
    "\n",
    "# Convert 'day', 'month', 'year' to a unified date column in 'train_selected' and 'test_selected'\n",
    "train_selected['date'] = pd.to_datetime(train_selected[['year', 'month', 'day']])\n",
    "test_selected['date'] = pd.to_datetime(test_selected[['year', 'month', 'day']])\n",
    "\n",
    "# Now split the dataset based on the cutoff date\n",
    "train_data = train_selected[train_selected['date'] < cutoff_date]\n",
    "test_data = test_selected[test_selected['date'] >= cutoff_date]\n",
    "\n",
    "# Separate features and target variable for training and testing sets\n",
    "X_train = train_data.drop([\"price\", \"id\",\"date\"], axis=1)\n",
    "y_train = train_data['price']\n",
    "X_test = test_data.drop([\"price\", \"id\",\"date\"], axis=1)\n",
    "y_test = test_data['price']\n",
    "\n",
    "# Initialize and train the model\n",
    "model = Ridge(alpha=1.0)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate the model\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model on the out-of-time testing data\n",
    "mse_score = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error (MSE):\", mse_score)\n",
    "\n",
    "# R-squared (R2) value calculated\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(\"R-squared (R2) Value:\", r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d6f148",
   "metadata": {},
   "source": [
    "## Lasso regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4690f15c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 15561.094846771619\n",
      "R-squared (R2) Value: 0.4796120135512477\n"
     ]
    }
   ],
   "source": [
    "#!pip install pandas scikit-learn xgboost matplotlib\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Lasso  # Importing Lasso\n",
    "\n",
    "\n",
    "# Split the data into features (X) and target variable (y)\n",
    "X = data_copy.drop(['price'], axis=1)\n",
    "y = data_copy['price']\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Instantiate Ridge Regressor\n",
    "# You can adjust the alpha parameter as needed, which controls the strength of regularization\n",
    "model = Lasso(alpha=1.0)\n",
    "\n",
    "# Fit the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "#MSE value calculated \n",
    "mse_score = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error (MSE):\", mse_score)\n",
    "\n",
    "#r2_score calculated\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(\"R-squared (R2) Value:\", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a610fe14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features Dropped: {'Mini fridge', 'gym', 'neighbourhood_Opéra', 'Blender', 'neighbourhood_Louvre', 'Board games', 'neighbourhood_Bourse', 'Breakfast', 'season_Autumn', 'is_school_holiday', 'neighbourhood_Entrepôt', 'neighbourhood_Hôtel-de-Ville', 'Rice maker', 'property_type_Other', 'neighbourhood_Gobelins', 'Radiant heating', 'Outdoor furniture', 'Outdoor dining area', 'pool', 'neighbourhood_Vaugirard', 'bbq', 'game console', 'sauna', 'weekday', 'neighbourhood_Panthéon', 'Bread maker', 'Piano', 'season_Winter', 'room_type_Shared room', 'neighbourhood_Batignolles-Monceau', 'day', 'exercise equipment', 'neighbourhood_Popincourt', 'Pets allowed', 'hot tub', 'Portable heater', 'season_Spring', 'neighbourhood_Palais-Bourbon', 'neighbourhood_Luxembourg', 'Sound system', 'neighbourhood_Observatoire', 'neighbourhood_Passy', 'is_holiday', 'season_Summer', 'neighbourhood_Buttes-Chaumont', 'neighbourhood_Reuilly', 'property_type_House', 'Cleaning available during stay'}\n",
      "Number of Features Dropped: 48\n",
      "Number of Features Remaining: 118\n",
      "Mean Squared Error: 15567.685599990227\n",
      "R-squared: 0.47939160818579074\n",
      "Adjusted R-squared: 0.47810725723694847\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "#X = data_copy.drop([\"price\"], axis=1)\n",
    "#y = data_copy['price']\n",
    "\n",
    "#original_features = data_copy.drop([\"price\"], axis=1).columns\n",
    "\n",
    "# Calculate feature importances\n",
    "#importances = mutual_info_classif(X, y)\n",
    "#feat_importances = pd.Series(importances, X.columns)\n",
    "\n",
    "# Set a threshold for feature importance (this is arbitrary and can be adjusted)\n",
    "#threshold = 0.01  # Example threshold\n",
    "\n",
    "# Select features above the importance threshold\n",
    "#selected_features = feat_importances[feat_importances > threshold].index\n",
    "\n",
    "# Rebuild the feature set with only selected features\n",
    "#X_selected = X[selected_features]\n",
    "\n",
    "# Number of features dropped\n",
    "#features_dropped = set(original_features) - set(selected_features)\n",
    "#num_features_dropped = len(features_dropped)\n",
    "\n",
    "# Number of features remaining\n",
    "#num_features_remaining = len(selected_features)\n",
    "\n",
    "# Print information about dropped and remaining features\n",
    "print(\"Features Dropped:\", features_dropped)\n",
    "print(\"Number of Features Dropped:\", num_features_dropped)\n",
    "print(\"Number of Features Remaining:\", num_features_remaining)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Train a Random Forest model\n",
    "rf = Lasso(alpha=1.0)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate the model\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "#looking at MSE\n",
    "from sklearn.metrics import mean_squared_error\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "\n",
    "# Calculate R-squared\n",
    "from sklearn.metrics import r2_score\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(\"R-squared:\", r2)\n",
    "\n",
    "# Calculate Adjusted R-squared\n",
    "n = X_test.shape[0]  # Number of observations\n",
    "p = X_test.shape[1]  # Number of predictor variables\n",
    "adjusted_r2 = 1 - (1 - r2) * (n - 1) / (n - p - 1)\n",
    "print(\"Adjusted R-squared:\", adjusted_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0c535b27",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anton\\AppData\\Local\\Temp\\ipykernel_42556\\3838728702.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_selected['date'] = pd.to_datetime(train_selected[['year', 'month', 'day']])\n",
      "C:\\Users\\anton\\AppData\\Local\\Temp\\ipykernel_42556\\3838728702.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_selected['date'] = pd.to_datetime(test_selected[['year', 'month', 'day']])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 17900.972207736362\n",
      "R-squared (R2) Value: 0.45446210797971764\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Get unique ids\n",
    "all_ids = data_copy['id'].unique()\n",
    "\n",
    "# Split ids into training and testing sets\n",
    "train_ids, test_ids = train_test_split(all_ids, test_size=0.3, random_state=42)\n",
    "\n",
    "# Filter data based on selected ids\n",
    "train_selected = data_copy[data_copy['id'].isin(train_ids)]\n",
    "test_selected = data_copy[data_copy['id'].isin(test_ids)]\n",
    "\n",
    "# Define the time cutoff date\n",
    "cutoff_date = pd.to_datetime('2023-11-24')  # Example: YYYY-MM-DD\n",
    "\n",
    "# Convert 'day', 'month', 'year' to a unified date column in 'train_selected' and 'test_selected'\n",
    "train_selected['date'] = pd.to_datetime(train_selected[['year', 'month', 'day']])\n",
    "test_selected['date'] = pd.to_datetime(test_selected[['year', 'month', 'day']])\n",
    "\n",
    "# Now split the dataset based on the cutoff date\n",
    "train_data = train_selected[train_selected['date'] < cutoff_date]\n",
    "test_data = test_selected[test_selected['date'] >= cutoff_date]\n",
    "\n",
    "# Separate features and target variable for training and testing sets\n",
    "X_train = train_data.drop([\"price\", \"id\",\"date\"], axis=1)\n",
    "y_train = train_data['price']\n",
    "X_test = test_data.drop([\"price\", \"id\",\"date\"], axis=1)\n",
    "y_test = test_data['price']\n",
    "\n",
    "# Initialize and train the model\n",
    "model = Lasso(alpha=1.0)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate the model\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model on the out-of-time testing data\n",
    "mse_score = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error (MSE):\", mse_score)\n",
    "\n",
    "# R-squared (R2) value calculated\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(\"R-squared (R2) Value:\", r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7def4a89",
   "metadata": {},
   "source": [
    "# XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d0491f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas scikit-learn xgboost matplotlib\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "\n",
    "# Split the data into features (X) and target variable (y)\n",
    "X = data_copy.drop(['price'], axis=1)\n",
    "y = data_copy['price']\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Instantiate XGBoost Regressor\n",
    "model = xgb.XGBRegressor()\n",
    "\n",
    "# Fit the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "#MSE value calculated \n",
    "mse_score = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error (MSE):\", mse_score)\n",
    "\n",
    "#r2_score calculated\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(\"R-squared (R2) Value:\", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e180ec38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "X = data_copy.drop([\"price\"], axis=1)\n",
    "y = data_copy['price']\n",
    "\n",
    "original_features = data_copy.drop([\"price\"], axis=1).columns\n",
    "\n",
    "# Calculate feature importances\n",
    "importances = mutual_info_classif(X, y)\n",
    "feat_importances = pd.Series(importances, X.columns)\n",
    "\n",
    "# Set a threshold for feature importance (this is arbitrary and can be adjusted)\n",
    "threshold = 0.01  # Example threshold\n",
    "\n",
    "# Select features above the importance threshold\n",
    "selected_features = feat_importances[feat_importances > threshold].index\n",
    "\n",
    "# Rebuild the feature set with only selected features\n",
    "X_selected = X[selected_features]\n",
    "\n",
    "# Number of features dropped\n",
    "features_dropped = set(original_features) - set(selected_features)\n",
    "num_features_dropped = len(features_dropped)\n",
    "\n",
    "# Number of features remaining\n",
    "num_features_remaining = len(selected_features)\n",
    "\n",
    "# Print information about dropped and remaining features\n",
    "print(\"Features Dropped:\", features_dropped)\n",
    "print(\"Number of Features Dropped:\", num_features_dropped)\n",
    "print(\"Number of Features Remaining:\", num_features_remaining)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Train a Random Forest model\n",
    "rf = xgb.XGBRegressor()\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate the model\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "#looking at MSE\n",
    "from sklearn.metrics import mean_squared_error\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "\n",
    "# Calculate R-squared\n",
    "from sklearn.metrics import r2_score\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(\"R-squared:\", r2)\n",
    "\n",
    "# Calculate Adjusted R-squared\n",
    "n = X_test.shape[0]  # Number of observations\n",
    "p = X_test.shape[1]  # Number of predictor variables\n",
    "adjusted_r2 = 1 - (1 - r2) * (n - 1) / (n - p - 1)\n",
    "print(\"Adjusted R-squared:\", adjusted_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ba3963",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Get unique ids\n",
    "all_ids = data_copy['id'].unique()\n",
    "\n",
    "# Split ids into training and testing sets\n",
    "train_ids, test_ids = train_test_split(all_ids, test_size=0.3, random_state=42)\n",
    "\n",
    "# Filter data based on selected ids\n",
    "train_selected = data_copy[data_copy['id'].isin(train_ids)]\n",
    "test_selected = data_copy[data_copy['id'].isin(test_ids)]\n",
    "\n",
    "# Define the time cutoff date\n",
    "cutoff_date = pd.to_datetime('2023-11-24')  # Example: YYYY-MM-DD\n",
    "\n",
    "# Convert 'day', 'month', 'year' to a unified date column in 'train_selected' and 'test_selected'\n",
    "train_selected['date'] = pd.to_datetime(train_selected[['year', 'month', 'day']])\n",
    "test_selected['date'] = pd.to_datetime(test_selected[['year', 'month', 'day']])\n",
    "\n",
    "# Now split the dataset based on the cutoff date\n",
    "train_data = train_selected[train_selected['date'] < cutoff_date]\n",
    "test_data = test_selected[test_selected['date'] >= cutoff_date]\n",
    "\n",
    "# Separate features and target variable for training and testing sets\n",
    "X_train = train_data.drop([\"price\", \"id\",\"date\"], axis=1)\n",
    "y_train = train_data['price']\n",
    "X_test = test_data.drop([\"price\", \"id\",\"date\"], axis=1)\n",
    "y_test = test_data['price']\n",
    "\n",
    "# Initialize and train the model\n",
    "model = xgb.XGBRegressor()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate the model\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model on the out-of-time testing data\n",
    "mse_score = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error (MSE):\", mse_score)\n",
    "\n",
    "# R-squared (R2) value calculated\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(\"R-squared (R2) Value:\", r2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
